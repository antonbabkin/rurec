{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERS Rurality codes\n",
    "\n",
    "This notebooks prepares [ERS rurality codes](https://www.ers.usda.gov/topics/rural-economy-population/rural-classifications/) for use in FSRDC.\n",
    "\n",
    "- Download Excel spreadsheets with code data and documentation.\n",
    "- Normalize column names.\n",
    "- Stack all years into a single dataframe and save it as CSV file.\n",
    "- Combine pieces of documentation and column renaming schemes into a text file. Text is tab-separated and can be loaded in tabular format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp ers_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rurec import resources\n",
    "from rurec.resources import Resource\n",
    "from rurec.util import download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources.add(Resource('ers/ruc', 'data/ers_codes/ruc/ruc.csv', 'ERS Rural-Urban Continuum codes - data'))\n",
    "resources.add(Resource('ers/ruc_doc', 'data/ers_codes/ruc/ruc_doc.txt', 'ERS Rural-Urban Continuum codes - documentation'))\n",
    "resources.add(Resource('ers/ui', 'data/ers_codes/ui/ui.csv', 'ERS Urban Influence codes - data'))\n",
    "resources.add(Resource('ers/ui_doc', 'data/ers_codes/ui/ui_doc.txt', 'ERS Urban Influence codes - documentation'))\n",
    "resources.add(Resource('ers/ruca', 'data/ers_codes/ruca/ruca.csv', 'ERS Rural-Urban Commuting Area codes - data'))\n",
    "resources.add(Resource('ers/ruca_doc', 'data/ers_codes/ruca/ruca_doc.txt', 'ERS Rural-Urban Commuting Area codes - documentation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ruc_dir = resources.get('ers/ruc').path.parent\n",
    "ui_dir = resources.get('ers/ui').path.parent\n",
    "ruca_dir = resources.get('ers/ruca').path.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and combine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rural-Urban Continuum Codes\n",
    "\n",
    "[Homepage](https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_and_combine_ruc():\n",
    "    \"\"\"Download Rural-Urban Continuum codes and documentation.\n",
    "    Combine all years of data into single CSV file.\n",
    "    Save all documentation into single TXT file.\"\"\"\n",
    "\n",
    "    ruc_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ruc_dfs = []\n",
    "    ruc_doc_dfs = []\n",
    "\n",
    "\n",
    "    # 1974\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53251/ruralurbancodes1974.xls?v=9631.3'\n",
    "    fname = download_file(url, ruc_dir / 'orig')\n",
    "    df = pd.read_excel(fname, dtype='str', nrows=3141)\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'County Name': 'COUNTY', '1974 Rural-urban Continuum Code': 'RUC_CODE'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df['RUC_YEAR'] = '1974'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUC 1974 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "        pd.DataFrame(['']),\n",
    "        pd.read_excel(fname, dtype='str', skiprows=3143, header=None).dropna(1, 'all')])\n",
    "    ruc_doc_dfs.append(df)\n",
    "\n",
    "\n",
    "    # 1983\n",
    "    # 1993 file is contained within 1983-1993 file. 2003 file repeats 1993 column.\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53251/cd8393.xls?v=9631.3'\n",
    "    fname = download_file(url, ruc_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fname, dtype='str')\n",
    "    cols_map = {'FIPS': 'FIPS', 'State': 'STATE', 'County Name': 'COUNTY', '1983 Rural-urban Continuum Code': 'RUC_CODE'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['RUC_YEAR'] = '1983'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUC 1983 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()])])\n",
    "    ruc_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # 1993\n",
    "    df = pd.read_excel(fname, dtype='str')\n",
    "    cols_map = {'FIPS': 'FIPS', 'State': 'STATE', 'County Name': 'COUNTY', '1993 Rural-urban Continuum Code': 'RUC_CODE'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['RUC_YEAR'] = '1993'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUC 1993 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()])])\n",
    "    ruc_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # 2003\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53251/ruralurbancodes2003.xls?v=9631.3'\n",
    "    fname = download_file(url, ruc_dir / 'orig')\n",
    "    df = pd.read_excel(fname, dtype='str')\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'County Name': 'COUNTY',\n",
    "                '2003 Rural-urban Continuum Code': 'RUC_CODE', '2000 Population ': 'POPULATION',\n",
    "                'Percent of workers in nonmetro counties commuting to central counties of adjacent metro areas': 'PERCENT_NONMETRO_COMMUTERS',\n",
    "                'Description for 2003 codes': 'RUC_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['RUC_YEAR'] = '2003'\n",
    "    df['POPULATION_YEAR'] = '2000'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUC 2003 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()])])\n",
    "    ruc_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # Puerto Rico 2003\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53251/pr2003.xls?v=9631.3'\n",
    "    fname = download_file(url, ruc_dir / 'orig')\n",
    "    df = pd.read_excel(fname, dtype='str')\n",
    "\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'Municipio Name': 'COUNTY', 'Population 2003 ': 'POPULATION',\n",
    "                'Rural-urban Continuum Code, 2003': 'RUC_CODE', 'Description of the 2003 Code': 'RUC_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['RUC_YEAR'] = '2003'\n",
    "    df['POPULATION_YEAR'] = '2003'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUC Puerto Rico 2003 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()])])\n",
    "    ruc_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # 2013\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53251/ruralurbancodes2013.xls?v=9631.3'\n",
    "    fname = download_file(url, ruc_dir / 'orig')\n",
    "    df = pd.read_excel(fname, 'Rural-urban Continuum Code 2013', dtype='str')\n",
    "    cols_map = {'FIPS': 'FIPS', 'State': 'STATE', 'County_Name': 'COUNTY', 'Population_2010': 'POPULATION',\n",
    "                'RUCC_2013': 'RUC_CODE', 'Description': 'RUC_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['RUC_YEAR'] = '2013'\n",
    "    df['POPULATION_YEAR'] = '2010'\n",
    "    ruc_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(['RUC 2013 documentation', '-' * 80, f'Data source: {url}']),\n",
    "                    pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "                    pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "                    pd.DataFrame(['']),\n",
    "                    pd.read_excel(fname, 'Documentation', header=None, dtype='str')])\n",
    "    ruc_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "    # Combine and save to disk\n",
    "    df = pd.concat(ruc_dfs)\n",
    "    df = df[['FIPS', 'STATE', 'COUNTY', 'RUC_YEAR', 'RUC_CODE', 'RUC_CODE_DESCRIPTION', \n",
    "             'POPULATION_YEAR', 'POPULATION', 'PERCENT_NONMETRO_COMMUTERS']]\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    df = df.sort_values(['FIPS', 'RUC_YEAR'])\n",
    "    out_fpath = ruc_dir / 'ruc.csv'\n",
    "    df.to_csv(out_fpath, index=False)\n",
    "    print(f'Saved combined data to {out_fpath}.')\n",
    "\n",
    "    df = pd.concat(ruc_doc_dfs)\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    out_fpath = ruc_dir / 'ruc_doc.txt'\n",
    "    df.to_csv(out_fpath, '\\t', header=False, index=False)\n",
    "    print(f'Saved documentation to {out_fpath}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban Influence Codes\n",
    "\n",
    "[Homepage](https://www.ers.usda.gov/data-products/urban-influence-codes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_and_combine_ui():\n",
    "    \"\"\"Download Urban Influence codes and documentation.\n",
    "    Combine all years of data into single CSV file.\n",
    "    Save all documentation into single TXT file.\"\"\"\n",
    "    ui_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ui_dfs = []\n",
    "    ui_doc_dfs = []\n",
    "\n",
    "    # 1993\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53797/UrbanInfluenceCodes.xls?v=1904.3'\n",
    "    fpath = download_file(url, ui_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fpath, 'Urban Influence Codes', dtype='str')\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'County name': 'COUNTY',\n",
    "                '2000 Population': 'POPULATION', '2000 Persons per square mile': 'POPULATION_DENSITY',\n",
    "                '1993 Urban Influence Code': 'UI_CODE', '1993 Urban Influence Code description': 'UI_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['UI_YEAR'] = '1993'\n",
    "    df['POPULATION_YEAR'] = '2000'\n",
    "    ui_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(['UI 1993 documentation', '-' * 80, f'Data source: {url}']),\n",
    "                    pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "                    pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "                    pd.DataFrame(['']),\n",
    "                    pd.read_excel(fpath, 'Information', header=None, dtype='str', skiprows=18)])\n",
    "\n",
    "    ui_doc_dfs.append(df)\n",
    "\n",
    "    # 2003\n",
    "    df = pd.read_excel(fpath, 'Urban Influence Codes', dtype='str')\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'County name': 'COUNTY',\n",
    "                '2003 Urban Influence Code': 'UI_CODE', '2003 Urban Influence Code description': 'UI_CODE_DESCRIPTION',\n",
    "                '2000 Population': 'POPULATION', '2000 Persons per square mile': 'POPULATION_DENSITY'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['UI_YEAR'] = '2003'\n",
    "    df['POPULATION_YEAR'] = '2000'\n",
    "    ui_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(['UI 2003 documentation', '-' * 80, f'Data source: {url}']),\n",
    "                    pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "                    pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "                    pd.DataFrame(['']),\n",
    "                    pd.read_excel(fpath, 'Information', header=None, dtype='str', skiprows=3, nrows=14)])\n",
    "    ui_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "    # Puerto Rico 2003\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53797/pr2003UrbInf.xls?v=1904.3'\n",
    "    fpath = download_file(url, ui_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fpath, dtype='str')\n",
    "    cols_map = {'FIPS Code': 'FIPS', 'State': 'STATE', 'Municipio Name': 'COUNTY', 'Population 2003 ': 'POPULATION',\n",
    "                'Urban Influence  Code, 2003': 'UI_CODE', 'Description of the 2003 Code': 'UI_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['UI_YEAR'] = '2003'\n",
    "    df['POPULATION_YEAR'] = '2003'\n",
    "    ui_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(['UI Puerto Rico 2003 documentation', '-' * 80, f'Data source: {url}']),\n",
    "                    pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "                    pd.DataFrame([[v, k] for k, v in cols_map.items()])])\n",
    "    ui_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "    # 2013\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53797/UrbanInfluenceCodes2013.xls?v=1904.3'\n",
    "    fpath = download_file(url, ui_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fpath, 'Urban Influence Codes 2013', dtype='str')\n",
    "    cols_map = {'FIPS': 'FIPS', 'State': 'STATE', 'County_Name': 'COUNTY', 'Population_2010': 'POPULATION',\n",
    "                'UIC_2013': 'UI_CODE', 'Description': 'UI_CODE_DESCRIPTION'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['UI_YEAR'] = '2013'\n",
    "    df['POPULATION_YEAR'] = '2010'\n",
    "    ui_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(['UI 2013 documentation', '-' * 80, f'Data source: {url}']),\n",
    "                    pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "                    pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "                    pd.DataFrame(['']),\n",
    "                    pd.read_excel(fpath, 'Documentation', header=None, dtype='str')])\n",
    "    ui_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "    # Combine and save to disk\n",
    "    df = pd.concat(ui_dfs)\n",
    "    df = df[['FIPS', 'STATE', 'COUNTY', 'UI_YEAR', 'UI_CODE', 'UI_CODE_DESCRIPTION', \n",
    "             'POPULATION_YEAR', 'POPULATION', 'POPULATION_DENSITY']]\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    df = df.sort_values(['FIPS', 'UI_YEAR'])\n",
    "    out_fpath = ui_dir / 'ui.csv'\n",
    "    df.to_csv(out_fpath, index=False)\n",
    "    print(f'Saved combined data to {out_fpath}.')\n",
    "\n",
    "    df = pd.concat(ui_doc_dfs)\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    out_fpath = ui_dir / 'ui_doc.txt'\n",
    "    df.to_csv(out_fpath, '\\t', header=False, index=False)\n",
    "    print(f'Saved documentation to {out_fpath}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rural-Urban Commuting Area Codes\n",
    "\n",
    "[Homepage](https://www.ers.usda.gov/data-products/rural-urban-commuting-area-codes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_and_combine_ruca():\n",
    "    \"\"\"Download Rural-Urban Commuting Area codes and documentation.\n",
    "    Combine all years of data into single CSV file.\n",
    "    Save all documentation into single TXT file.\"\"\"\n",
    "    ruca_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ruca_dfs = []\n",
    "    ruca_doc_dfs = []\n",
    "\n",
    "    # 1990\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53241/ruca1990.xls?v=9882.5'\n",
    "    fname = download_file(url, ruca_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fname, 'Data', dtype='str')\n",
    "    cols_map = {'FIPS state-county-tract code': 'FIPS',\n",
    "                'Rural-urban commuting area code': 'RUCA_CODE',\n",
    "                'Census tract population, 1990': 'POPULATION',\n",
    "                'Census tract land area, square miles, 1990': 'AREA',\n",
    "                'County metropolitan status, 1993 (1=metro,0=nonmetro)': 'METRO'}\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['FIPS'] = df['FIPS'].str.replace('.', '')\n",
    "    df['YEAR'] = '1990'\n",
    "    ruca_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUCA 1990 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "        pd.DataFrame(['']),\n",
    "        pd.read_excel(fname, 'RUCA code description', header=None, dtype='str'),\n",
    "        pd.DataFrame(['', 'Data sources']),\n",
    "        pd.read_excel(fname, 'Data sources', header=None, dtype='str')])\n",
    "    ruca_doc_dfs.append(df)\n",
    "\n",
    "\n",
    "    # 2000\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53241/ruca00.xls?v=9882.5'\n",
    "    fname = download_file(url, ruca_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fname, 'Data', dtype='str')\n",
    "\n",
    "    cols_map = {\n",
    "        'Select State': 'STATE',\n",
    "        'Select County ': 'COUNTY',\n",
    "        'State County Tract Code': 'FIPS',\n",
    "        'RUCA Secondary Code 2000': 'RUCA_CODE',\n",
    "        'Tract Population 2000': 'POPULATION'\n",
    "    }\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['YEAR'] = '2000'\n",
    "    ruca_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUCA 2000 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "        pd.DataFrame(['']),\n",
    "        pd.read_excel(fname, 'RUCA code description', header=None, dtype='str'),\n",
    "        pd.DataFrame(['', 'Data sources']),\n",
    "        pd.read_excel(fname, 'Data sources', header=None, dtype='str')])\n",
    "    ruca_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # 2010\n",
    "    url = 'https://www.ers.usda.gov/webdocs/DataFiles/53241/ruca2010revised.xlsx?v=9882.5'\n",
    "    fname = download_file(url, ruca_dir / 'orig')\n",
    "\n",
    "    df = pd.read_excel(fname, 'Data', dtype='str', skiprows=1)\n",
    "    cols_map = {\n",
    "        'Select State': 'STATE',\n",
    "        'Select County': 'COUNTY',\n",
    "        'State-County-Tract FIPS Code (lookup by address at http://www.ffiec.gov/Geocode/)': 'FIPS',\n",
    "        'Secondary RUCA Code, 2010 (see errata)': 'RUCA_CODE',\n",
    "        'Tract Population, 2010': 'POPULATION',\n",
    "        'Land Area (square miles), 2010': 'AREA'\n",
    "    }\n",
    "    df = df.rename(columns=cols_map)\n",
    "    df = df[cols_map.values()]\n",
    "    df['YEAR'] = '2010'\n",
    "    ruca_dfs.append(df)\n",
    "\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(['RUCA 2010 documentation', '-' * 80, f'Data source: {url}']),\n",
    "        pd.DataFrame([[''], ['Column names'], ['Renamed', 'Original']]),\n",
    "        pd.DataFrame([[v, k] for k, v in cols_map.items()]),\n",
    "        pd.DataFrame(['']),\n",
    "        pd.read_excel(fname, 'RUCA code description', header=None, dtype='str'),\n",
    "        pd.DataFrame(['', 'Data sources']),\n",
    "        pd.read_excel(fname, 'Data sources', header=None, dtype='str')])\n",
    "    ruca_doc_dfs.extend([pd.DataFrame(['', '']), df])\n",
    "\n",
    "\n",
    "    # Combine and save to disk\n",
    "    df = pd.concat(ruca_dfs)\n",
    "    df = df[['FIPS', 'STATE', 'COUNTY', 'YEAR', 'RUCA_CODE', 'POPULATION', 'AREA', 'METRO']]\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    df = df.sort_values(['FIPS', 'YEAR'])\n",
    "    out_fpath = ruca_dir / 'ruca.csv'\n",
    "    df.to_csv(out_fpath, index=False)\n",
    "    print(f'Saved combined data to {out_fpath}.')\n",
    "\n",
    "    df = pd.concat(ruca_doc_dfs)\n",
    "    for col in df:\n",
    "        df[col] = df[col].str.strip()\n",
    "    out_fpath = ruca_dir / 'ruca_doc.txt'\n",
    "    df.to_csv(out_fpath, '\\t', header=False, index=False)\n",
    "    print(f'Saved documentation to {out_fpath}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_and_combine_all():\n",
    "    \"\"\"Download and prepare RUC, UI and RUCA code datasets.\"\"\"\n",
    "    download_and_combine_ruc()\n",
    "    download_and_combine_ui()\n",
    "    download_and_combine_ruca()\n",
    "\n",
    "def get_ruc_df():\n",
    "    \"\"\"Return `pandas.DataFrame` of Rural-Urban Continuum codes for all years.\"\"\"\n",
    "    res = resources.get('ers/ruc')\n",
    "    df = pd.read_csv(res.path, dtype='str')\n",
    "    for c in ['RUC_YEAR', 'POPULATION_YEAR', 'POPULATION', 'PERCENT_NONMETRO_COMMUTERS']:\n",
    "        df[c] = pd.to_numeric(df[c])\n",
    "    cats = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    df['RUC_CODE'] = pd.Categorical(df['RUC_CODE'], cats, True)\n",
    "    return df\n",
    "\n",
    "def get_ui_df():\n",
    "    \"\"\"Return `pandas.DataFrame` of Urban Influence codes for all years.\"\"\"\n",
    "    res = resources.get('ers/ui')\n",
    "    df = pd.read_csv(res.path, dtype='str')\n",
    "    for c in ['UI_YEAR', 'POPULATION_YEAR', 'POPULATION', 'POPULATION_DENSITY']:\n",
    "        df[c] = pd.to_numeric(df[c])\n",
    "    cats = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "    df['UI_CODE'] = pd.Categorical(df['UI_CODE'], cats, True)\n",
    "    return df\n",
    "\n",
    "def get_ruca_df():\n",
    "    \"\"\"Return `pandas.DataFrame` of Rural-Urban Commuting Area codes for all years.\"\"\"\n",
    "    res = resources.get('ers/ruca')\n",
    "    df = pd.read_csv(res.path, dtype='str')\n",
    "    for c in ['YEAR', 'POPULATION', 'AREA']:\n",
    "        # ValueError: Unable to parse string \"6 23.063\" at position 269\n",
    "        # todo: input files probably had this error, add manual fix to `download_and_convert_ruca()`\n",
    "        df[c] = pd.to_numeric(df[c], 'coerce')\n",
    "    cats = ['1', '1.1', \n",
    "            '2', '2.1', '2.2', \n",
    "            '3', \n",
    "            '4', '4.1', '4.2', \n",
    "            '5', '5.1', '5.2', \n",
    "            '6', '6.1', \n",
    "            '7', '7.1', '7.2', '7.3', '7.4', \n",
    "            '8', '8.1', '8.2', '8.3', '8.4', \n",
    "            '9', '9.1', '9.2', \n",
    "            '10', '10.1', '10.2', '10.3', '10.4', '10.5', '10.6', \n",
    "            '99']\n",
    "    df['RUCA_CODE'] = df['RUCA_CODE'].str.replace('.0', '', regex=False)\n",
    "    df['RUCA_CODE'] = pd.Categorical(df['RUCA_CODE'], cats, True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive summary\n",
    "\n",
    "Simple visualization of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rural-Urban Continuum Codes\n",
    "\n",
    "Documentation notes that not all years are directly comparable.\n",
    "\n",
    "In 1974, 1983 and 1993 there was code \"0\", join it with \"1\" for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "df = get_ruc_df()\n",
    "df['RUC_CODE'] = df['RUC_CODE'].replace('0', '1')\n",
    "df['POPULATION'] = df.groupby('FIPS')['POPULATION'].fillna(method='bfill')\n",
    "\n",
    "stats = df.groupby(['RUC_YEAR', 'RUC_CODE'])['POPULATION'].agg(['size', 'sum'])\n",
    "stats['sum'] /= 1000\n",
    "stats.columns = ['Counties', 'Population']\n",
    "stats = stats.astype(int).unstack()\n",
    "\n",
    "# 2003 and 2013 codes are identical\n",
    "codes = (df.loc[df['RUC_YEAR'] == 2013, ['RUC_CODE', 'RUC_CODE_DESCRIPTION']]\n",
    "         .dropna().drop_duplicates()\n",
    "         .sort_values('RUC_CODE')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "data = stats['Counties']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "idx = [str(x) for x in data.index]\n",
    "bottom = pd.Series([0] * len(data), index=data.index)\n",
    "for code in data:\n",
    "    ax.bar(idx, data[code], bottom=bottom, label=code)\n",
    "    bottom += data[code]\n",
    "\n",
    "dummy = mpl.patches.Patch(fill=False, edgecolor='none')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles = [dummy] + handles[:3] + [dummy] + handles[3:6] + [dummy] + handles[6:]\n",
    "labels = ['metro'] + labels[:3] + ['nonmetro'] + labels[3:6] + [''] + labels[6:]\n",
    "ax.legend(handles, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "ax.set_title('Number of counties by Rural-Urban Continuum code')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population\n",
    "\n",
    "No population in dataset before 2010, so 2010 is used for earlier years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "data = stats['Population']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "idx = [str(x) for x in data.index]\n",
    "bottom = pd.Series([0] * len(data), index=data.index)\n",
    "for code in data:\n",
    "    ax.bar(idx, data[code], bottom=bottom, label=code)\n",
    "    bottom += data[code]\n",
    "\n",
    "dummy = mpl.patches.Patch(fill=False, edgecolor='none')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles = [dummy] + handles[:3] + [dummy] + handles[3:6] + [dummy] + handles[6:]\n",
    "labels = ['metro'] + labels[:3] + ['nonmetro'] + labels[3:6] + [''] + labels[6:]\n",
    "ax.legend(handles, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "ax.set_title('Population in thousands by Rural-Urban Continuum code')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban-Influence Codes\n",
    "\n",
    "I have no idea if these are comparable across time, so I am going to pretend they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "\n",
    "df = get_ui_df()\n",
    "\n",
    "# df['UI_CODE']=df['UI_CODE'].str.zfill(2)\n",
    "         \n",
    "df['POPULATION'] = df.groupby('FIPS')['POPULATION'].fillna(method='bfill')\n",
    "\n",
    "stats = df.groupby(['UI_YEAR', 'UI_CODE'])['POPULATION'].agg(['size', 'sum'])\n",
    "stats['sum'] /= 1000\n",
    "stats.columns = ['Counties', 'Population']\n",
    "stats = stats.astype(int).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2003 and 2013 codes are identical\n",
    "codes = (df.loc[df['UI_YEAR'] == 2013, ['UI_CODE', 'UI_CODE_DESCRIPTION']]\n",
    "         .dropna().drop_duplicates()\n",
    "         .sort_values('UI_CODE')\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "data = stats['Counties']\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "idx = [str(x) for x in data.index]\n",
    "bottom = pd.Series([0] * len(data), index=data.index)\n",
    "for code in data:\n",
    "    ax.bar(idx, data[code], bottom=bottom, label=code)\n",
    "    bottom += data[code]\n",
    "    \n",
    "dummy = mpl.patches.Patch(fill=False, edgecolor='none')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles = [dummy] + handles[:2] + [dummy] + handles[2:7] + [dummy] + handles[7:10] + [dummy] + handles[10:12]\n",
    "labels = ['metro'] + labels[:2] + ['metro adj'] + labels[2:7] + ['micro'] + labels[7:10] + ['rural'] + labels[10:12]\n",
    "ax.legend(handles, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "ax.set_title('Number of Counties by UI Codes')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "data = stats['Population']\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "idx = [str(x) for x in data.index]\n",
    "bottom = pd.Series([0] * len(data), index=data.index)\n",
    "for code in data:\n",
    "    ax.bar(idx, data[code], bottom=bottom, label=code)\n",
    "    bottom += data[code]\n",
    "    \n",
    "dummy = mpl.patches.Patch(fill=False, edgecolor='none')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles = [dummy] + handles[:2] + [dummy] + handles[2:7] + [dummy] + handles[7:10] + [dummy] + handles[10:12]\n",
    "labels = ['metro'] + labels[:2] + ['metro adj'] + labels[2:7] + ['micro'] + labels[7:10] + ['rural'] + labels[10:12]\n",
    "ax.legend(handles, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "ax.set_title('Population by UI Codes')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_ruc_df()\n",
    "assert df.shape == (15864, 9)\n",
    "assert df['RUC_CODE'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_ui_df()\n",
    "assert df.shape == (9583, 9)\n",
    "assert df['UI_CODE'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_ruca_df()\n",
    "assert df.shape == (200581, 8)\n",
    "assert df['RUCA_CODE'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need more tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
