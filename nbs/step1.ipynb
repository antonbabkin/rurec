{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fips = {\n",
    "'AL':'01',\n",
    "'AK':'02',\n",
    "'AS':'60',\n",
    "'AZ':'04',\n",
    "'AR':'05',\n",
    "'CA':'06',\n",
    "'CO':'08',\n",
    "'CT':'09',\n",
    "'DE':'10',\n",
    "'DC':'11',\n",
    "'FL':'12',\n",
    "'FM':'64',\n",
    "'GA':'13',\n",
    "'GU':'66',\n",
    "'HI':'15',\n",
    "'ID':'16',\n",
    "'IL':'17',\n",
    "'IN':'18',\n",
    "'IA':'19',\n",
    "'KS':'20',\n",
    "'KY':'21',\n",
    "'LA':'22',\n",
    "'ME':'23',\n",
    "'MH':'68',\n",
    "'MD':'24',\n",
    "'MA':'25',\n",
    "'MI':'26',\n",
    "'MN':'27',\n",
    "'MS':'28',\n",
    "'MO':'29',\n",
    "'MT':'30',\n",
    "'NE':'31',\n",
    "'NV':'32',\n",
    "'NH':'33',\n",
    "'NJ':'34',\n",
    "'NM':'35',\n",
    "'NY':'36',\n",
    "'NC':'37',\n",
    "'ND':'38',\n",
    "'MP':'69',\n",
    "'OH':'39',\n",
    "'OK':'40',\n",
    "'OR':'41',\n",
    "'PW':'70',\n",
    "'PA':'42',\n",
    "'PR':'72',\n",
    "'RI':'44',\n",
    "'SC':'45',\n",
    "'SD':'46',\n",
    "'TN':'47',\n",
    "'TX':'48',\n",
    "'UM':'74',\n",
    "'UT':'49',\n",
    "'VT':'50',\n",
    "'VA':'51',\n",
    "'VI':'78',\n",
    "'WA':'53',\n",
    "'WV':'54',\n",
    "'WI':'55',\n",
    "'WY':'56'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_correct(yr):\n",
    "    print(f'\\n{yr}:')\n",
    "    print(f'\\n{yr}:',file=logfile)\n",
    "    dir = '/InfoGroup/data/original/'\n",
    "    xdir = '/tmp/xtrcts/'\n",
    "    fname = f'{yr}_Business_Academic_QCQ_utf-8'\n",
    "    # Extract the annual file from the zip archive\n",
    "    with ZipFile(f'{dir}{fname}.zip','r') as myzip:\n",
    "        myzip.extract(f'{fname}.csv',f'{xdir}')\n",
    "        df = pd.read_csv(f'{xdir}{fname}.csv',low_memory=False,dtype=object)\n",
    "    \n",
    "    # Delete the temp file\n",
    "    os.remove(f'{xdir}{fname}.csv')  \n",
    "    \n",
    "    # Add 'State Code' column, the 2-digit FIPS code\n",
    "    df['State Code'] = df['State'].apply(lambda s: state_fips[s])\n",
    "    # Correct and overwrite the state FIPS code.\n",
    "    df['FIPS Code'] = df['State Code'] + df['County Code']\n",
    "    \n",
    "    # Add Full Census Tract column, the 11-digit census tract identifying\n",
    "    # a tract uniquely nationwide. The 'Census Tract' variable in InfoGroup\n",
    "    # is the 6-digit code that identifies a tract only within a county.\n",
    "    df['Full Census Tract'] = df['FIPS Code'] + df['Census Tract']\n",
    "    # zero-fill the ZipCode value\n",
    "    df['ZipCode'] = df['ZipCode'].apply(lambda x: x.zfill(5) if len(x) < 5 == 0 else x)\n",
    "    return df\n",
    "\n",
    "def CBSA_partition(df):    \n",
    "    urban = df[~df['CBSA Level'].isnull()]\n",
    "    rural = df[(~df['CBSA Code'].isnull()) & (df['CBSA Level'].isnull())]\n",
    "    unknown = df[df['CBSA Code'] .isnull()]\n",
    "\n",
    "    nrows = len(df)\n",
    "    sum_of_parts = len(urban) + len(rural) + len(unknown)\n",
    "    if sum_of_parts != nrows:\n",
    "        print('Error in dividing enterprises into categories:',file=logfile)\n",
    "        print(f'\\t{nrows} != {sum_of_parts}',file=logfile)\n",
    "        \n",
    "    corrected = extract_corrections(unknown)\n",
    "    corrected.drop(columns=['CBSA','LSAD'],inplace=True)\n",
    "    corrected.rename(columns={\"FIPS Code_l\": \"FIPS Code\"},inplace=True)\n",
    "\n",
    "    print(corrected['CBSA Level'].value_counts(),file=logfile)\n",
    "    print(len(corrected[corrected['CBSA Level'].isnull()]),file=logfile)\n",
    "    return (urban, rural, corrected)\n",
    "\n",
    "def extract_corrections(unknowns):\n",
    "    \"\"\"Extracts CBSA Code and appropriate CBSA Level for a list of InfoGroup FIPS Codes\"\"\"\n",
    "    unknowns['FIPS Code'] = unknowns['FIPS Code'].astype(str)\n",
    "    unk = unknowns.merge(cbsa_df,on='FIPS Code',how='inner') \n",
    "    unk['CBSA Level'] = np.nan\n",
    "    \n",
    "    for i in unk.index:\n",
    "        if unk.at[i,'LSAD'].find(\"Metropolitan\") > -1:\n",
    "            unk.at[i,'CBSA Level'] = 2\n",
    "        elif unk.at[i,'LSAD'].find(\"Micropolitan\") > -1:\n",
    "            unk.at[i,'CBSA Level'] = 1    \n",
    "    return unk\n",
    "    \n",
    "def showtime(num):\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(str(num),'  ',dt_string)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference datasets and derived data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census relationship file: cross-references CBSA codes and state/county FIPS codes.\n",
    "# Variable 'STCOU' is the 5-digit state/county FIPS code. The CBSA Level is inferred from the\n",
    "# text in the 'LSAD' variable.\n",
    "cbsa_df = pd.read_csv(f'/InfoGroup/data/rurality/reference/relationships/cbsa-county-relationships-2017.csv',\n",
    "                      usecols=['STCOU','CBSA','LSAD'],dtype=object)   \n",
    "cbsa_df.rename(columns={'STCOU':'FIPS Code'},inplace=True)\n",
    "cbsa_df['FIPS Code'] = cbsa_df['FIPS Code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a log file.\n",
    "logfile = open('/InfoGroup/data/rurality/logs/step1.log','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for yr in range(1997,2018):\n",
    "for yr in range(2017,2018):\n",
    "    showtime('start')\n",
    "    df = extract_and_correct(yr)\n",
    "    showtime('extract_and_correct')\n",
    "    (urban,rural,corrected) = CBSA_partition(df)\n",
    "    showtime('CBSA_partition')\n",
    "    final_df = pd.concat([urban,rural,corrected],ignore_index=True)\n",
    "    showtime('inline concat')\n",
    "    final_df.to_csv(f'/InfoGroup/data/rurality/step1_{yr}.csv',index=None)\n",
    "    showtime('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
