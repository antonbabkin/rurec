{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate geo variables in InfoGroup\n",
    "\n",
    "> Test for consistency across different spatial variables and correct errors when possible.\n",
    "\n",
    "- Create 11-digit census tract identifier\n",
    "- Fill missing CBSA codes from FIPS reference\n",
    "\n",
    "## Possible future work\n",
    "\n",
    "- Correct 2-digit state part of the FIPS code.\n",
    "- Correct missing CBSA code and CBSA level, mainly in 2009.\n",
    "- Validations:\n",
    "  - codes are valid (i.e. can be found in lookup tables) for fields such as SIC, NAICS, FIPS, CBSA_CODE etc.\n",
    "  - geo variable consistency: CBSA_LEVEL vs CBSA_CODE, lon-lat, nesting of areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is not supposed to work and was moved over from step1 for reference.\n",
    "# Needs revision and integration in overall workflow.\n",
    "\n",
    "def extract_and_correct(yr):\n",
    "    print(f'\\n{yr}:')\n",
    "    print(f'\\n{yr}:',file=logfile)\n",
    "    dir = '/InfoGroup/data/original/'\n",
    "    xdir = '/tmp/xtrcts/'\n",
    "    fname = f'{yr}_Business_Academic_QCQ_utf-8'\n",
    "    # Extract the annual file from the zip archive\n",
    "    with ZipFile(f'{dir}{fname}.zip','r') as myzip:\n",
    "        myzip.extract(f'{fname}.csv',f'{xdir}')\n",
    "        df = pd.read_csv(f'{xdir}{fname}.csv',low_memory=False,dtype=object)\n",
    "    \n",
    "    # Delete the temp file\n",
    "    os.remove(f'{xdir}{fname}.csv')  \n",
    "    \n",
    "    # Add 'State Code' column, the 2-digit FIPS code\n",
    "    df['State Code'] = df['State'].apply(lambda s: state_fips[s])\n",
    "    # Correct and overwrite the state FIPS code.\n",
    "    df['FIPS Code'] = df['State Code'] + df['County Code']\n",
    "    \n",
    "    # Add Full Census Tract column, the 11-digit census tract identifying\n",
    "    # a tract uniquely nationwide. The 'Census Tract' variable in InfoGroup\n",
    "    # is the 6-digit code that identifies a tract only within a county.\n",
    "    df['Full Census Tract'] = df['FIPS Code'] + df['Census Tract']\n",
    "    # zero-fill the ZipCode value\n",
    "    df['ZipCode'] = df['ZipCode'].apply(lambda x: x.zfill(5) if len(x) < 5 == 0 else x)\n",
    "    return df\n",
    "\n",
    "def CBSA_partition(df):    \n",
    "    urban = df[~df['CBSA Level'].isnull()]\n",
    "    rural = df[(~df['CBSA Code'].isnull()) & (df['CBSA Level'].isnull())]\n",
    "    unknown = df[df['CBSA Code'] .isnull()]\n",
    "\n",
    "    nrows = len(df)\n",
    "    sum_of_parts = len(urban) + len(rural) + len(unknown)\n",
    "    if sum_of_parts != nrows:\n",
    "        print('Error in dividing enterprises into categories:',file=logfile)\n",
    "        print(f'\\t{nrows} != {sum_of_parts}',file=logfile)\n",
    "        \n",
    "    corrected = extract_corrections(unknown)\n",
    "    corrected.drop(columns=['CBSA','LSAD'],inplace=True)\n",
    "    corrected.rename(columns={\"FIPS Code_l\": \"FIPS Code\"},inplace=True)\n",
    "\n",
    "    print(corrected['CBSA Level'].value_counts(),file=logfile)\n",
    "    print(len(corrected[corrected['CBSA Level'].isnull()]),file=logfile)\n",
    "    return (urban, rural, corrected)\n",
    "\n",
    "def extract_corrections(unknowns):\n",
    "    \"\"\"Extracts CBSA Code and appropriate CBSA Level for a list of InfoGroup FIPS Codes\"\"\"\n",
    "    unknowns['FIPS Code'] = unknowns['FIPS Code'].astype(str)\n",
    "    unk = unknowns.merge(cbsa_df,on='FIPS Code',how='inner') \n",
    "    unk['CBSA Level'] = np.nan\n",
    "    \n",
    "    for i in unk.index:\n",
    "        if unk.at[i,'LSAD'].find(\"Metropolitan\") > -1:\n",
    "            unk.at[i,'CBSA Level'] = 2\n",
    "        elif unk.at[i,'LSAD'].find(\"Micropolitan\") > -1:\n",
    "            unk.at[i,'CBSA Level'] = 1    \n",
    "    return unk\n",
    "    \n",
    "def showtime(num):\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(str(num),'  ',dt_string)\t\n",
    "\n",
    "## Reference datasets and derived data structures\n",
    "\n",
    "# Census relationship file: cross-references CBSA codes and state/county FIPS codes.\n",
    "# Variable 'STCOU' is the 5-digit state/county FIPS code. The CBSA Level is inferred from the\n",
    "# text in the 'LSAD' variable.\n",
    "cbsa_df = pd.read_csv(f'/InfoGroup/data/rurality/reference/relationships/cbsa-county-relationships-2017.csv',\n",
    "                      usecols=['STCOU','CBSA','LSAD'],dtype=object)   \n",
    "cbsa_df.rename(columns={'STCOU':'FIPS Code'},inplace=True)\n",
    "cbsa_df['FIPS Code'] = cbsa_df['FIPS Code'].astype(str)\n",
    "\n",
    "## Main\n",
    "\n",
    "# Open a log file.\n",
    "logfile = open('/InfoGroup/data/rurality/logs/step1.log','w')\n",
    "\n",
    "#for yr in range(1997,2018):\n",
    "for yr in range(2017,2018):\n",
    "    showtime('start')\n",
    "    df = extract_and_correct(yr)\n",
    "    showtime('extract_and_correct')\n",
    "    (urban,rural,corrected) = CBSA_partition(df)\n",
    "    showtime('CBSA_partition')\n",
    "    final_df = pd.concat([urban,rural,corrected],ignore_index=True)\n",
    "    showtime('inline concat')\n",
    "    final_df.to_csv(f'/InfoGroup/data/rurality/step1_{yr}.csv',index=None)\n",
    "    showtime('finished')\n",
    "\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of geographic variables\n",
    "\n",
    "Geographic variables\n",
    "\n",
    "- ADDRESS: historical address\n",
    "- CITY: historical address city\n",
    "- STATE: historical address state\n",
    "- ZIP: historical address zip code\n",
    "- ZIP4: historical address zip code zip + 4\n",
    "- COUNTY_CODE: county code based upon location address/zip4 (postal)\n",
    "- AREA_CODE: area code of business\n",
    "- ADDRESS_TYPE: indicates if type of address. \"F\": \"Firm\", \"G\": \"General delivery\", \"H\": \"High-rise\", \"M\": \"Military\", \"P\": \"Post office box\", \"R\": \"Rural route or hwy contract\", \"S\": \"Street\", \"N\": \"Unknown\", \"\": \"No match to Zip4\".\n",
    "- CENSUS_TRACT: identifies a small geographic area for the purpose of collecting and compiling population and housing data.  census tracts are unique only within census county, and census counties are unique only within census state.  \n",
    "- CENSUS_BLOCK: bgs are subdivisions of census tracts and unique only within a specific census tract.  census tracts/block groups are assigned to address records via a geocoding process.\n",
    "- LATITUDE: parcel level assigned via point geo coding.  half of a pair of coordinates (the other being longitude)  provided in a formatted value, with decimals or a negative sign. not available in puerto rico & virgin island.\n",
    "- LONGITUDE: parcel level assigned via point geo coding.  note: longitudes are negatives values in the western hemisphere.  provided in its formatted value, with decimals or a negative sign. not available in puerto rico & virigin island\n",
    "- MATCH_CODE: parcel level match code of the business location. \"0\": \"Site level\", \"2\": \"Zip+2 centroid\", \"4\": \"Zip+4 centroid\", \"P\": \"Parcel\", \"X\": \"Zip centroid\".\n",
    "- CBSA_CODE: core bases statistical area (expanded msa code)\n",
    "- CBSA_LEVEL: indicates if an area is a micropolitan or metropolitan area. \"1\": \"Micropolitan\", \"2\": \"Metropolitan\"\n",
    "- CSA_CODE: adjoining cbsa's.  combination of metro and micro areas\n",
    "- FIPS_CODE: first 2 bytes = state code, last 3 bytes = county code (location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = ['ADDRESS', 'CITY', 'STATE', 'ZIP', 'ZIP4', 'COUNTY_CODE', 'AREA_CODE', 'ADDRESS_TYPE', \n",
    "            'CENSUS_TRACT', 'CENSUS_BLOCK', 'LATITUDE', 'LONGITUDE', 'MATCH_CODE', \n",
    "            'CBSA_CODE', 'CBSA_LEVEL', 'CSA_CODE', 'FIPS_CODE']\n",
    "total_count = {}\n",
    "isna_count = {}\n",
    "other_count = {}\n",
    "\n",
    "for year in range(1997, 2018):\n",
    "    df = get_df(year, cols=geo_cols)\n",
    "\n",
    "    total_count[year] = len(df)\n",
    "\n",
    "    isna_count[year] = {}\n",
    "    for col in geo_cols:\n",
    "        isna_count[year][col] = df[col].isna().sum()\n",
    "\n",
    "    other_count[year] = {}\n",
    "    other_count[year]['ADDRESS_TYPE'] = (df['ADDRESS_TYPE'] == 'N').sum()\n",
    "    other_count[year]['CENSUS_TRACT'] = (df['CENSUS_TRACT'] == '000000').sum() # is 000000 a valid tract id?\n",
    "    other_count[year]['CENSUS_BLOCK'] = (df['CENSUS_BLOCK'] == '0').sum() # is 0 a valid block id?\n",
    "    other_count[year]['CBSA_CODE'] = (df['CBSA_CODE'] == '00000').sum()\n",
    "    other_count[year]['CSA_CODE'] = (df['CSA_CODE'] == '000').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATE, COUNTY_CODE and FIPS_CODE\n",
    "\n",
    "- STATE is never missing\n",
    "- Tiny fraction (0.0001%) have missing COUNTY_CODE or FIPS_CODE\n",
    "- Until 2012, about 2% have inconsistent codes, and only a few after that\n",
    "  - Can correct using either STATE or state part of FIPS_CODE as truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fips_map = {\n",
    "'AL':'01',\n",
    "'AK':'02',\n",
    "'AS':'60',\n",
    "'AZ':'04',\n",
    "'AR':'05',\n",
    "'CA':'06',\n",
    "'CO':'08',\n",
    "'CT':'09',\n",
    "'DE':'10',\n",
    "'DC':'11',\n",
    "'FL':'12',\n",
    "'FM':'64',\n",
    "'GA':'13',\n",
    "'GU':'66',\n",
    "'HI':'15',\n",
    "'ID':'16',\n",
    "'IL':'17',\n",
    "'IN':'18',\n",
    "'IA':'19',\n",
    "'KS':'20',\n",
    "'KY':'21',\n",
    "'LA':'22',\n",
    "'ME':'23',\n",
    "'MH':'68',\n",
    "'MD':'24',\n",
    "'MA':'25',\n",
    "'MI':'26',\n",
    "'MN':'27',\n",
    "'MS':'28',\n",
    "'MO':'29',\n",
    "'MT':'30',\n",
    "'NE':'31',\n",
    "'NV':'32',\n",
    "'NH':'33',\n",
    "'NJ':'34',\n",
    "'NM':'35',\n",
    "'NY':'36',\n",
    "'NC':'37',\n",
    "'ND':'38',\n",
    "'MP':'69',\n",
    "'OH':'39',\n",
    "'OK':'40',\n",
    "'OR':'41',\n",
    "'PW':'70',\n",
    "'PA':'42',\n",
    "'PR':'72',\n",
    "'RI':'44',\n",
    "'SC':'45',\n",
    "'SD':'46',\n",
    "'TN':'47',\n",
    "'TX':'48',\n",
    "'UM':'74',\n",
    "'UT':'49',\n",
    "'VT':'50',\n",
    "'VA':'51',\n",
    "'VI':'78',\n",
    "'WA':'53',\n",
    "'WV':'54',\n",
    "'WI':'55',\n",
    "'WY':'56'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=resources.paths.root/'tmp/geo_valid.log', level=logging.INFO, format='%(message)s', force=True)\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(message)s', force=True)\n",
    "crosstabs = {}\n",
    "for year in range(1997, 2018):\n",
    "    df = get_df(year, cols=['STATE', 'COUNTY_CODE', 'FIPS_CODE'])\n",
    "\n",
    "    df['_STATE_CODE'] = df['STATE'].map(state_fips_map, 'ignore')\n",
    "    state_isna = df['STATE'].isna()\n",
    "    state_isna.name = 'STATE is NA'\n",
    "    county_isna = df['COUNTY_CODE'].isna()\n",
    "    county_isna.name = 'COUNTY_CODE is NA'\n",
    "    fips_isna = df.FIPS_CODE.isna()\n",
    "    fips_isna.name = 'FIPS_CODE is NA'\n",
    "    county_eq_fips = (df['COUNTY_CODE'] == df['FIPS_CODE'].str[2:])\n",
    "    county_eq_fips.name = 'COUNTY_CODE consistent with FIPS_CODE'\n",
    "    state_eq_fips = (df['_STATE_CODE'] == df['FIPS_CODE'].str[:2])\n",
    "    state_eq_fips.name = 'STATE consistent with FIPS_CODE'\n",
    "\n",
    "    crosstab = pd.crosstab([state_isna, county_isna, fips_isna], [county_eq_fips, state_eq_fips])\n",
    "    crosstabs[year] = crosstab.stack([0, 1])\n",
    "    logging.info(f'''\n",
    "    ---- {year} ----\n",
    "    STATE, COUNTY_CODE and FIPS_CODE consistency\n",
    "\n",
    "    {crosstab}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.concat(crosstabs).unstack(0).fillna(0).astype(int).T\n",
    "ct = ct.loc[:, ~(ct == 0).all()].droplevel(0, 1)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = pd.DataFrame()\n",
    "ctf['Valid'] = ct.loc[:, (False, False, True, True)]\n",
    "ctf['Missing COUNTY_CODE or FIPS_CODE'] = ct[True].sum(1) + ct[(False, True,)].iloc[:, 0]\n",
    "ctf['Inconsistent codes'] = ct.sum(1) - ctf.sum(1)\n",
    "pd.testing.assert_series_equal(ct.sum(1), ctf.sum(1))\n",
    "ctf.loc['Total', :] = ctf.sum()\n",
    "ctf['Total'] = ctf.sum(1)\n",
    "ctf = ctf.astype(int)\n",
    "ctf.style.format('{:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctfr = ctf.copy()\n",
    "for c in ctfr:\n",
    "    ctfr[c] /= ctfr['Total']\n",
    "ctfr.style.format('{:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBSA_CODE and CBSA_LEVEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
