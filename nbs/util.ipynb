{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_file(url, dir=None, fname=None, overwrite=False):\n",
    "    \"\"\"Download file from given `url` and put it into `dir`.\n",
    "    Current working directory is used as default. Missing directories are created.\n",
    "    File name from `url` is used as default.\n",
    "    Return absolute pathlib.Path of the downloaded file.\"\"\"\n",
    "    \n",
    "    if dir is None:\n",
    "        dir = '.'\n",
    "    dpath = Path(dir).resolve()\n",
    "    dpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if fname is None:\n",
    "        fname = Path(urlparse(url).path).name\n",
    "    fpath = dpath / fname\n",
    "    \n",
    "    if not overwrite and fpath.exists():\n",
    "        print(f'File {fname} already exists.')\n",
    "        return fpath\n",
    "\n",
    "    with requests.get(url) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(fpath, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    \n",
    "    print(f'Downloaded file {fname}.')\n",
    "    return fpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tag_invalid_values(ser, notna=False, unique=False, nchar=None, number=False, cats=None,\n",
    "                 eq=None, gt=None, ge=None, lt=None, le=None):\n",
    "    \"\"\"Return array with indicators of invalid values in `ser`.\n",
    "\n",
    "    Validity checks are performed against flags given as keyword arguments.\n",
    "    If multiple flags are present, value is only valid if it satisfies all of them.\n",
    "    \n",
    "    If a value is missing, it will be marked invalid by `notna` flag.\n",
    "    IMPORTANT: missing values will NOT be flagged invalid by any other flags.\n",
    "    \n",
    "    `unique` will tag all duplicates as invalid.\n",
    "    \"\"\"\n",
    "    # idea: print warning if unsupported values are present, e.g. str values with \"ge\" flag\n",
    "    valid = np.ones_like(ser, np.bool)\n",
    "    ser_isna = ser.isna()\n",
    "    ser_notna = ~ser_isna\n",
    "    \n",
    "    if notna:\n",
    "        valid &= ser_notna\n",
    "        \n",
    "    if unique:\n",
    "        valid &= (ser_isna | ~ser.duplicated(False))\n",
    "    \n",
    "    if nchar is not None:\n",
    "        valid &= (ser_isna | (ser.str.len() == nchar))\n",
    "        \n",
    "    if number:\n",
    "        conversion_fail = ser_notna & pd.to_numeric(ser, 'coerce').isna()\n",
    "        valid &= (ser_isna | ~conversion_fail)\n",
    "        \n",
    "    if cats is not None:\n",
    "        valid &= (ser_isna | ser.isin(cats))\n",
    "        \n",
    "    if eq is not None:\n",
    "        valid &= (ser_isna | (ser == eq))\n",
    "    if gt is not None:\n",
    "        valid &= (ser_isna | (ser > gt))\n",
    "    if ge is not None:\n",
    "        valid &= (ser_isna | (ser >= ge))\n",
    "    if lt is not None:\n",
    "        valid &= (ser_isna | (ser < lt))\n",
    "    if le is not None:\n",
    "        valid &= (ser_isna | (ser <= le))\n",
    "        \n",
    "    return ~valid.values\n",
    "        \n",
    "\n",
    "def validate_values(df, constraints):\n",
    "    \"\"\"Return list of invalid values in a dataframe.\n",
    "    `constraints` should be a dictionary of column names and \n",
    "    their respective constraints as dict to be passed to validator function.\n",
    "    \"\"\"\n",
    "    invalid_list = []\n",
    "    for col, flags in constraints.items():\n",
    "        inval_bool = tag_invalid_values(df[col], **flags)\n",
    "        inval_row_idx, = inval_bool.nonzero()\n",
    "        for i in inval_row_idx:\n",
    "            invalid_list.append({'col': col, 'row': i, 'idx': df.index[i], 'val': df[col].iloc[i]})\n",
    "            \n",
    "    return invalid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['alpha', 'beta', 'beta', '0123', np.nan], dtype='str')\n",
    "assert (tag_invalid_values(s, notna=True) == [False, False, False, False, True]).all()\n",
    "assert (tag_invalid_values(s, unique=True) == [False, True, True, False, False]).all()\n",
    "assert (tag_invalid_values(s, nchar=4) == [True, False, False, False, False]).all()\n",
    "assert (tag_invalid_values(s, number=True) == [True, True, True, False, False]).all()\n",
    "assert (tag_invalid_values(s, cats=['alpha', 'beta']) == [False, False, False, True, False]).all()\n",
    "assert (tag_invalid_values(s, eq='beta') == [True, False, False, True, False]).all()\n",
    "\n",
    "s = pd.Series([1, 7.5, -99999999, np.nan])\n",
    "assert (tag_invalid_values(s, notna=True) == [False, False, False, True]).all()\n",
    "assert (tag_invalid_values(s, unique=True) == [False, False, False, False]).all()\n",
    "assert (tag_invalid_values(s, cats=[1, 7.5]) == [False, False, True, False]).all()\n",
    "assert (tag_invalid_values(s, eq=1) == [False, True, True, False]).all()\n",
    "assert (tag_invalid_values(s, ge=0) == [False, False, True, False]).all()\n",
    "assert (tag_invalid_values(s, le=0) == [True, True, False, False]).all()\n",
    "assert (tag_invalid_values(s, gt=1, lt=10) == [True, False, True, False]).all()\n",
    "assert (tag_invalid_values(s, ge=1, lt=10) == [False, False, True, False]).all()\n",
    "assert (tag_invalid_values(s, gt=10, lt=0) == [True, True, True, False]).all()\n",
    "\n",
    "s = pd.Series([np.nan, 15, '15', '-15', '.15', '1.5', '-.15', '-1.5', '1a', 'ab', ''])\n",
    "assert (tag_invalid_values(s, number=True) == 8 * [False] + 3 * [True]).all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
