{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGroup data\n",
    "\n",
    "> Process and prepare InfoGroup dataset.\n",
    "\n",
    "- toc: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "Starting from original CSV files.\n",
    "\n",
    "- Convert to unicode\n",
    "- Validate against JSON schema. A few erroneous data entries are erased here (e.g. text in numerical column). Existing implementation uses datapackage validator and takes several days with single core.\n",
    "- Save to disk in parquet format.\n",
    "- Provide interface to load single year of data. Allow filtering, column selection and small (optionally random) sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export infogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import gzip\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "from IPython import display\n",
    "from joblib import Memory\n",
    "\n",
    "from rurec import resources\n",
    "from rurec.resources import Resource\n",
    "from rurec import util\n",
    "\n",
    "memory = Memory(resources.paths['root'] / 'cache')\n",
    "data_years = range(1997, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# for batch runs: log to a file\n",
    "logging.basicConfig(filename=resources.paths['root'] / 'logs/processing.log', \n",
    "                    filemode='w', level=logging.INFO, format='%(asctime)s %(levelname)s:\\n%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for interactive use: log to stdout\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s %(levelname)s:\\n%(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources.add(Resource('infogroup/schema', '/InfoGroup/data/processed/schema.json', 'Processed InfoGroup data, schema', False))\n",
    "resources.add(Resource('infogroup/full', '/InfoGroup/data/processed/full.pq', 'Processed InfoGroup data, all years, partitioned parquet', False))\n",
    "for y in data_years:\n",
    "    resources.add(Resource(f'infogroup/orig/{y}', f'/InfoGroup/data/original/raw/{y}_Business_Academic_QCQ.csv', f'Original unprocessed InfoGroup data, {y}', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override resource paths for testing and debugging\n",
    "resources.get('infogroup/full').path = resources.paths['root'] / 'tmp/full.pq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster returns for testing and debugging\n",
    "pd.read_csv = functools.partial(pd.read_csv, nrows=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear and validate raw data\n",
    "\n",
    "- Change \"latin-1\" encoding to \"utf-8\", remove double quotes around values.\n",
    "- Remove double quotes around every value.\n",
    "- Rename columns to ALL_CAPS.\n",
    "- In 2009: pad string fields with zeroes.\n",
    "- Validate values format, replace errors with missing values.\n",
    "\n",
    "### Future work\n",
    "\n",
    "- Correct 2-digit state part of the FIPS code.\n",
    "- Correct missing CBSA code and CBSA level, mainly in 2009.\n",
    "- add indicator variables for different samples (random, WI, FAI, ...) to be used as parquet partitions to allow quick read of data subsets\n",
    "- put meaningfult labels to categoricals (\"1-5\" instead if \"A\" etc).\n",
    "  - This will be tricky for POPULATION_CODE that changes coding between 2015 and 2016\n",
    "- make up and add enum constraints for TITLE_CODE and CALL_STATUS_CODE\n",
    "- add logging of errors to a file\n",
    "- if categoricals are worthy on fields with large number of unique values, possible unknown a priori, such as city or NAICS, then they should be applied. care should be taken because set of unique values can vary between years, and it might create problems when merging.\n",
    "- validations:\n",
    "  - codes are valid (i.e. can be found in lookup tables) for fields such as SIC, NAICS, FIPS, CBSA_CODE etc.\n",
    "  - geo variable consistency: CBSA_LEVEL vs CBSA_CODE, lon-lat, nesting of areas\n",
    "- few variables have many values like \"00000\", those should possibly be replaced with np.nan\n",
    "  - subsidiary_number, parent_number, site_number, census_tract, csa_code, maybe others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "def convert_schema(datapackage_schema_path):\n",
    "    \"\"\"Convert old datapackage schema.json into a new file, to be used for data validation.\"\"\"\n",
    "    sch0 = json.load(open(datapackage_schema_path))\n",
    "\n",
    "    def get_field_years(field_name):\n",
    "        years = []\n",
    "        for fl in sch0['field_lists']:\n",
    "            if field_name in fl['fields']:\n",
    "                years += fl['years']\n",
    "        if 2015 in years:\n",
    "            years += [2016, 2017]\n",
    "        if field_name == 'gender':\n",
    "            years += [2017]\n",
    "        return sorted(years)\n",
    "\n",
    "\n",
    "    sch = dict()\n",
    "    sch['info'] = 'Schema for cleaned InfoGroup data.'\n",
    "    sch['fields'] = list()\n",
    "\n",
    "    for f0 in sch0['fields']:\n",
    "        f = dict()\n",
    "        name = f0['name']\n",
    "        f['name'] = name.upper()\n",
    "        f['years'] = get_field_years(name)\n",
    "        if 'enum' in f0['constraints']:\n",
    "            enum = f0['constraints']['enum'].copy()\n",
    "            if '' in enum:\n",
    "                enum.pop(enum.index(''))\n",
    "            f['enum'] = enum\n",
    "        if 'values' in f0:\n",
    "            values = f0['values'].copy()\n",
    "            if name == 'cbsa_level':\n",
    "                del values['0'] # code never used\n",
    "            f['enum_labels'] = values\n",
    "\n",
    "        field_widths = {\n",
    "            'ZIP': 5,\n",
    "            'ZIP4': 4,\n",
    "            'COUNTY_CODE': 3,\n",
    "            'AREA_CODE': 3,\n",
    "            'PHONE': 7,\n",
    "            'SIC': 6,\n",
    "            'SIC0': 6,\n",
    "            'SIC1': 6,\n",
    "            'SIC2': 6,\n",
    "            'SIC3': 6,\n",
    "            'SIC4': 6,\n",
    "            'NAICS': 8,\n",
    "            'YP_CODE': 5,\n",
    "            'ABI': 9,\n",
    "            'SUBSIDIARY_NUMBER': 9,\n",
    "            'PARENT_NUMBER': 9,\n",
    "            'SITE_NUMBER': 9,\n",
    "            'CENSUS_TRACT': 6,\n",
    "            'CENSUS_BLOCK': 1,\n",
    "            'CBSA_CODE': 5,\n",
    "            'CSA_CODE': 3,\n",
    "            'FIPS_CODE': 5\n",
    "        }\n",
    "        if f['name'] in field_widths:\n",
    "            f['width'] = field_widths[f['name']]\n",
    "\n",
    "        f['original_name'] = f0['originalName']\n",
    "        f['original_description'] = f0['originalDescription']\n",
    "        sch['fields'].append(f)\n",
    "\n",
    "    json.dump(sch, open(resources.get('infogroup/schema').path, 'w'), indent=1)\n",
    "    \n",
    "\n",
    "def get_schema(field_name=None, year=None):\n",
    "    \"\"\"Flexible function to get dataset schema.\n",
    "    \n",
    "    With no parameters, return full list of field dictionaries.\n",
    "    With `year`, restrict to fields present in that year.\n",
    "    With `field_name`, return dictionary for specific field (`year` is ignored in this case).\n",
    "    \"\"\"\n",
    "    sch = json.load(resources.get(f'infogroup/schema').path.open())['fields']\n",
    "    if field_name is not None:\n",
    "        return [x for x in sch if x['name'] == field_name][0]\n",
    "    if year is not None:\n",
    "        return [x for x in sch if year in x['years']]\n",
    "    return sch  \n",
    "\n",
    "    \n",
    "def pad_with_zeroes(df, schema_fields):\n",
    "    \"\"\"Prepend string column values with zeroes to have constant width.\"\"\"\n",
    "\n",
    "    for field in schema_fields:\n",
    "        if 'width' in field:\n",
    "            df[field['name']] = df[field['name']].str.zfill(field['width'])\n",
    "\n",
    "def validate_raw_strings(df, schema_fields):\n",
    "    \"\"\"Validate values in raw InfoGroup data according to string constraints.\n",
    "    Return list of dicts of invalid values.\n",
    "    \"\"\"\n",
    "    \n",
    "    constraints = {\n",
    "        'ZIP': {'number': True},\n",
    "        'ZIP4': {'number': True},\n",
    "        'COUNTY_CODE': {'number': True},\n",
    "        'AREA_CODE': {'number': True},\n",
    "        'PHONE': {'number': True},\n",
    "        'SIC': {'number': True},\n",
    "        'SIC0': {'number': True},\n",
    "        'SIC1': {'number': True},\n",
    "        'SIC2': {'number': True},\n",
    "        'SIC3': {'number': True},\n",
    "        'SIC4': {'number': True},\n",
    "        'NAICS': {'number': True},\n",
    "        'YEAR': {'notna': True, 'number': True},\n",
    "        'YP_CODE': {'number': True},\n",
    "        'EMPLOYEES': {'number': True},\n",
    "        'SALES': {'number': True},\n",
    "        'PARENT_EMPLOYEES': {'number': True},\n",
    "        'PARENT_SALES': {'number': True},\n",
    "        'YEAR_EST': {'number': True},\n",
    "        'ABI': {'unique': True, 'notna': True, 'number': True},\n",
    "        'SUBSIDIARY_NUMBER': {'number': True},\n",
    "        'PARENT_NUMBER': {'number': True},\n",
    "        'SITE_NUMBER': {'number': True},\n",
    "        'CENSUS_TRACT': {'number': True},\n",
    "        'CENSUS_BLOCK': {'number': True},\n",
    "        'LATITUDE': {'number': True},\n",
    "        'LONGITUDE': {'number': True},\n",
    "        'CBSA_CODE': {'number': True},\n",
    "        'CSA_CODE': {'number': True},\n",
    "        'FIPS_CODE': {'number': True}\n",
    "    }\n",
    "    \n",
    "    # the above hard coded list of constraints must be consistent with field availability in given year\n",
    "    constraints = {k: v for k, v in constraints.items() if k in df}\n",
    "    \n",
    "    \n",
    "    for field in schema_fields:\n",
    "        name = field['name']\n",
    "        if 'enum' in field:\n",
    "            if name not in constraints: constraints[name] = dict()\n",
    "            constraints[name]['cats'] = field['enum']\n",
    "        if 'width' in field:\n",
    "            constraints[name]['nchar'] = field['width']\n",
    "    \n",
    "    return util.validate_values(df, constraints)\n",
    "\n",
    "\n",
    "def convert_dtypes(df, schema_fields):\n",
    "    \"\"\"Inplace convert string columns to appropriate types.\"\"\"\n",
    "    \n",
    "    for col in ['YEAR', 'EMPLOYEES', 'SALES', 'PARENT_EMPLOYEES', 'PARENT_SALES', 'YEAR_EST', 'LATITUDE', 'LONGITUDE']:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "        \n",
    "    for field in schema_fields:\n",
    "        if 'enum' in field:\n",
    "            df[field['name']] = pd.Categorical(df[field['name']], categories=field['enum'])\n",
    "    \n",
    "\n",
    "def validate_raw_numbers(df, year):\n",
    "    \"\"\"Validate values in raw InfoGroup data according to numerical constraints.\n",
    "    Return list of dicts of invalid values.\n",
    "    \"\"\"\n",
    "    \n",
    "    constraints = {\n",
    "        'YEAR': {'eq': year},\n",
    "        'EMPLOYEES': {'ge': 0},\n",
    "        'SALES': {'ge': 0},\n",
    "        'PARENT_EMPLOYEES': {'ge': 0},\n",
    "        'PARENT_SALES': {'ge': 0},\n",
    "        'YEAR_EST': {'ge': 1000, 'le': year},\n",
    "        'LATITUDE': {'ge': 0, 'le': 90},\n",
    "        'LONGITUDE': {'ge': -180, 'le': 0}\n",
    "    }\n",
    "    return util.validate_values(df, constraints)\n",
    "\n",
    "def replace_invalid(df, invalid_list, replacement=np.nan):\n",
    "    \"\"\"Replace invalid values.\"\"\"\n",
    "    for inv in invalid_list:\n",
    "        df.loc[inv['idx'], inv['col']] = replacement\n",
    "        logging.info(f'Replace invalid value `{inv[\"val\"]}` with `{replacement}` at .loc[{inv[\"idx\"]}, \\'{inv[\"col\"]}\\']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_schema('/InfoGroup/data/original/raw/datapackage_schema.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# Columns that do not appear in all years, as well as POPULATION_CODE that changes categories,\n",
    "# are not includes in the full parquet dataset\n",
    "shared_cols = [x['name']\n",
    "               for x in json.load(resources.get('infogroup/schema').path.open())['fields']\n",
    "               if (1997 in x['years']) and (x['name'] not in ['YEAR', 'POPULATION_CODE'])]\n",
    "\n",
    "def load_validate_convert(year):\n",
    "    \"\"\"Run full processing pipeline on one year of data:\n",
    "    load CVS, validate values, convert dtypes and save as parquet partition.\n",
    "    \"\"\"\n",
    "    logging.info(f'Processing started for year {year}\\n' + '-'*80)\n",
    "    sch = json.load(resources.get(f'infogroup/schema').path.open())\n",
    "    sch = [x for x in sch['fields'] if year in x['years']]\n",
    "    \n",
    "    # POPULATION_CODE has different values in 2016 and 2017\n",
    "    if year >= 2016:\n",
    "        for f in sch:\n",
    "            if f['name'] == 'POPULATION_CODE':\n",
    "                f['enum'] = list('0123456789')\n",
    "                break\n",
    "\n",
    "    df = pd.read_csv(resources.get(f'infogroup/orig/{year}').path, dtype='str', encoding='latin-1')\n",
    "\n",
    "    df.rename(columns={x['original_name']: x['name'] for x in sch}, inplace=True)\n",
    "\n",
    "    if year == 2009:\n",
    "        pad_with_zeroes(df, sch)\n",
    "\n",
    "    invalid_str = validate_raw_strings(df, sch)\n",
    "    if len(invalid_str) < 100:\n",
    "        replace_invalid(df, invalid_str)\n",
    "    else:\n",
    "        logging.error(f'Very many invalid_str values: {len(invalid_str)}, processing aborted')\n",
    "        logging.error(invalid_str[:5])\n",
    "        return\n",
    "\n",
    "    convert_dtypes(df, sch)\n",
    "\n",
    "    invalid_num = validate_raw_numbers(df, year)\n",
    "    if len(invalid_num) < 100:\n",
    "        replace_invalid(df, invalid_num)\n",
    "    else:\n",
    "        logging.error(f'Very many invalid_num values: {len(invalid_num)}, processing aborted')\n",
    "        logging.error(invalid_num[:5])\n",
    "        return\n",
    "    \n",
    "    df = df[shared_cols]\n",
    "    partition_path = str(resources.get('infogroup/full').path / f'YEAR={year}')\n",
    "    fastparquet.write(partition_path, df, file_scheme='hive', write_index=False, partition_on=['STATE'])\n",
    "\n",
    "    logging.info(f'Processing finished for year {year}\\n' + '-'*80)\n",
    "    return partition_path\n",
    "\n",
    "\n",
    "def build_parquet_dataset(n_cpus=1):\n",
    "    \"\"\"Create full parquet dataset from yearly CSV files.\"\"\"\n",
    "    \n",
    "    logging.info('create_parquet_dataset() started.')\n",
    "    \n",
    "    p = resources.get('infogroup/full').path\n",
    "    # Remove dataset files if they exist from before\n",
    "    if p.exists():\n",
    "        shutil.rmtree(p)\n",
    "    p.mkdir()\n",
    "    if n_cpus > 1:\n",
    "        with mp.Pool(n_cpus) as pool:\n",
    "            partition_paths = pool.map(load_validate_convert, data_years)\n",
    "    else:\n",
    "        partition_paths = [load_validate_convert(y) for y in data_years]\n",
    "    _ = fastparquet.writer.merge(partition_paths)\n",
    "    logging.info('create_parquet_dataset() finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_df(years=None, cols=None, states=None):\n",
    "    \"\"\"Return one year of InfoGroup data with appropriate data types.\n",
    "    Subset of columns can be loaded by passing list to `cols`.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    if years is not None:\n",
    "        filters.append(('YEAR', 'in', years))\n",
    "    if states is not None:\n",
    "        filters.append(('STATE', 'in', states))\n",
    "    res = resources.get('infogroup/full')\n",
    "    df = pd.read_parquet(res.path, 'fastparquet', columns=cols, filters=filters)\n",
    "    df['YEAR'] = df['YEAR'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive summary statistics\n",
    "\n",
    "Missing counts are reported as captured by `isna()` method. This will include empty strings from raw CSV for string dtype.\n",
    "\n",
    "Some variables also have a special value such as \"000\" which is reported separately. These special values are not documented, and so are discovered by inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "@memory.cache\n",
    "def describe_variable(col, df=None, distribution=False, count_values=[]):\n",
    "    \"\"\"Return summary statistics of `col` for all years of data.\n",
    "\n",
    "    Dataframe is read from disk unless given in `df`.\n",
    "    Distribution moments are reported by setting `distribution` to True.\n",
    "    Counts of values specified in `count_values` are reported.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None:\n",
    "        df = get_df(cols=['YEAR', col])\n",
    "        \n",
    "    stats = {}\n",
    "    stats['Total'] = df.groupby('YEAR').size()\n",
    "    stats['Total']['All'] = len(df)\n",
    "    df['__FLAG'] = df[col].notna()\n",
    "    stats['Not missing'] = df.groupby('YEAR')['__FLAG'].sum().astype(int)\n",
    "    stats['Not missing']['All'] = stats['Not missing'].sum()\n",
    "    stats['Missing'] = stats['Total'] - stats['Not missing']\n",
    "    stats['Unique'] = df.groupby('YEAR')[col].nunique()\n",
    "    stats['Unique']['All'] = df[col].nunique()\n",
    "\n",
    "    if distribution:\n",
    "        stats['Min'] = df.groupby('YEAR')[col].min()\n",
    "        stats['Min']['All'] = stats['Min'].min()\n",
    "        stats['Max'] = df.groupby('YEAR')[col].max()\n",
    "        stats['Max']['All'] = stats['Max'].max()\n",
    "        stats['Mean'] = df.groupby('YEAR')[col].mean()\n",
    "        stats['Mean']['All'] = df[col].mean()\n",
    "        stats['s.d.'] = df.groupby('YEAR')[col].std()\n",
    "        stats['s.d.']['All'] = df[col].std()\n",
    "        q = df.groupby('YEAR')[col].quantile([0.25, 0.5, 0.75]).unstack()\n",
    "        qa = df[col].quantile([0.25, 0.5, 0.75])\n",
    "        stats['25%'] = q[0.25]\n",
    "        stats['25%']['All'] = qa[0.25]\n",
    "        stats['50% (median)'] = q[0.5]\n",
    "        stats['50% (median)']['All'] = qa[0.5]\n",
    "        stats['75%'] = q[0.75]\n",
    "        stats['75%']['All'] = qa[0.75]\n",
    "\n",
    "    for val in count_values:\n",
    "        df['__FLAG'] = (df[col] == val)\n",
    "        stats[f'Value \"{val}\"'] = df.groupby('YEAR')['__FLAG'].sum().astype(int)\n",
    "        stats[f'Value \"{val}\"']['All'] = stats[f'Value \"{val}\"'].sum()\n",
    "\n",
    "    return pd.concat(stats, 1)\n",
    "\n",
    "\n",
    "def style(df):\n",
    "    \"\"\"Apply formatting style to summary stats dataframe.\"\"\"\n",
    "\n",
    "    f = {}\n",
    "    int_cols = ['Total', 'Not missing', 'Missing', 'Unique']\n",
    "    int_cols += [c for c in df if c.startswith('Value \"')]\n",
    "    for c in int_cols:\n",
    "        f[c] = '{:,}'\n",
    "    for c in ['Min', 'Max', 'Mean', 's.d.', '25%', '50% (median)', '75%']:\n",
    "        f[c] = '{:,g}'\n",
    "\n",
    "    return df.style.format(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPANY**: Name of business - will have blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('COMPANY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADDRESS**: Historical address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ADDRESS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CITY**: Historical address city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CITY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STATE**: Historical address state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('STATE', count_values=get_schema('STATE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ZIP**: Historical address zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ZIP'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ZIP4**: Historical address zip code zip + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ZIP4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COUNTY_CODE**: County code based upon location address/zip4 (postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('COUNTY_CODE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AREA_CODE**: Area code of business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('AREA_CODE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID_CODE**: The code that indentifies the yellow page listing is for a business or for an individual.  this field helps clients indentify if the record represents a professional indivisual versus a firm record.  \n",
    "Value labels:  \n",
    "1: Individual  \n",
    "2: Firm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ID_CODE', count_values=get_schema('ID_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMPLOYEES_CODE**: Code indicating range of employees at that location  \n",
    "Value labels:  \n",
    "A: 1-4  \n",
    "B: 5-9  \n",
    "C: 10-19  \n",
    "D: 20-49  \n",
    "E: 50-99  \n",
    "F: 100-249  \n",
    "G: 250-499  \n",
    "H: 500-999  \n",
    "I: 1000-4999  \n",
    "J: 5000-9999  \n",
    "K: 10000-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('EMPLOYEES_CODE', count_values=get_schema('EMPLOYEES_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SALES_CODE**: Corporate sales volume code (ranges) represents the total sales company wide  \n",
    "Value labels:  \n",
    "A: 1-499  \n",
    "B: 500-999  \n",
    "C: 1000-2499  \n",
    "D: 2500-4999  \n",
    "E: 5000-9999  \n",
    "F: 10000-19999  \n",
    "G: 20000-49999  \n",
    "H: 50000-99999  \n",
    "I: 100000-499999  \n",
    "J: 500000-999999  \n",
    "K: 1000000+  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SALES_CODE', count_values=get_schema('SALES_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC**: This field contains the 6-digit sic code for the business’s primary activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC_DESC**: The desciption for the sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAICS**: The desciption for the primary naics code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('NAICS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAICS_DESC**: The desciption for the naics code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('NAICS_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC0**: A line of business that company engages in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC0_DESC**: The desciption for the sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC0_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC1**: This field identifies an additional activity of the business.  if there is no additional activity, this field will be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC1_DESC**: The desciption for the secondary sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC1_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC2**: This field identifies an additional activity of the business.  if there is no additional activity, this field will be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC2_DESC**: The desciption for the secondary sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC2_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC3**: This field identifies an additional activity of the business.  if there is no additional activity, this field will be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC3_DESC**: The desciption for the secondary sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC3_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC4**: This field identifies an additional activity of the business.  if there is no additional activity, this field will be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIC4_DESC**: The desciption for the secondary sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SIC4_DESC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YEAR**: Year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('YEAR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YP_CODE**: A numeric value assigned to yellow page heading for the sic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('YP_CODE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMPLOYEES**: Number of employees at that location, could be modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('EMPLOYEES', distribution=True, count_values=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SALES**: Sales volume at that location (in thousands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SALES', distribution=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUSINESS_STATUS**: Indicates if record is hq, sub, or branch  \n",
    "Value labels:  \n",
    "1: headquarters  \n",
    "2: branch  \n",
    "3: subsidiary  \n",
    "9: standalone  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('BUSINESS_STATUS', count_values=get_schema('BUSINESS_STATUS')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IND_BYTE**: Contains \"number of\" info.  (# beds for nursing homes, # rooms for hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('IND_BYTE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YEAR_EST**: Year the business began operating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('YEAR_EST'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OFFICE_SIZE_CODE**: Number of professionals per office with the same phone number  \n",
    "Value labels:  \n",
    "A: 1  \n",
    "B: 2  \n",
    "C: 3  \n",
    "D: 4  \n",
    "E: 5-9  \n",
    "F: 10+  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('OFFICE_SIZE_CODE', count_values=get_schema('OFFICE_SIZE_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOLDING_STATUS**: Indicates if company is a public company, private company, or a branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('HOLDING_STATUS', count_values=get_schema('HOLDING_STATUS')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ABI**: Also known as iusa number, abi number, infogroup number or location number, this provides a unique identifier for each business in the infogroup business database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ABI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUBSIDIARY_NUMBER**: The subsidiary parent number identifies the business as a regional or subsidiary headquarters for a corporate family. the subsidiary will always have a parent and may or may not have branches assigned to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SUBSIDIARY_NUMBER'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARENT_NUMBER**: The parent number identifies the corporate parent of the business and also serves as the abi number for the headquarters site of the parent.  since all location of a business have the same ultimate parent number, this field provides ‘corporate ownwership’ linkage infomration.  this iinformation is not collected or maintained for the types organiation for wich ownership is ambiguous.  churches and schools, in particular, are not linked in the file for this reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('PARENT_NUMBER'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARENT_EMPLOYEES**: Parent actual employee size refers to the parent abi record only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('PARENT_EMPLOYEES', distribution=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARENT_SALES**: Parent actual sales refers to the parent abi record only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('PARENT_SALES', distribution=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARENT_EMPLOYEES_CODE**: Parent employee code refers to the parent abi record only  \n",
    "Value labels:  \n",
    "A: 1-4  \n",
    "B: 5-9  \n",
    "C: 10-19  \n",
    "D: 20-49  \n",
    "E: 50-99  \n",
    "F: 100-249  \n",
    "G: 250-499  \n",
    "H: 500-999  \n",
    "I: 1000-4999  \n",
    "J: 5000-9999  \n",
    "K: 10000-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('PARENT_EMPLOYEES_CODE', count_values=get_schema('PARENT_EMPLOYEES_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARENT_SALES_CODE**: Parent sales code refers to the parent abi records only  \n",
    "Value labels:  \n",
    "A: 1-499  \n",
    "B: 500-999  \n",
    "C: 1000-2499  \n",
    "D: 2500-4999  \n",
    "E: 5000-9999  \n",
    "F: 10000-19999  \n",
    "G: 20000-49999  \n",
    "H: 50000-99999  \n",
    "I: 100000-499999  \n",
    "J: 500000-999999  \n",
    "K: 1000000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('PARENT_SALES_CODE', count_values=get_schema('PARENT_SALES_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SITE_NUMBER**: Designates related business at one site, identifying the primary business.  if abi# and site# are the same, then the record is primary business at the site.  if abi# and site# are different, then the record is a secondary business at the site.  determined through relationships between multiple data elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('SITE_NUMBER'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADDRESS_TYPE**: Indicates if type of address  \n",
    "Value labels:  \n",
    "F: Firm  \n",
    "G: General delivery  \n",
    "H: High-rise  \n",
    "M: Military  \n",
    "P: Post office box  \n",
    "R: Rural route or hwy contract  \n",
    "S: Street  \n",
    "N: Unknown  \n",
    ": No match to Zip4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('ADDRESS_TYPE', count_values=get_schema('ADDRESS_TYPE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CENSUS_TRACT**: Identifies a small geographic area for the purpose of collecting and compiling population and housing data.  census tracts are unique only within census county, and census counties are unique only within census state.\n",
    "\n",
    "Special value \"000000\" - missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CENSUS_TRACT', count_values=['000000']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CENSUS_BLOCK**: Bgs are subdivisions of census tracts and unique only within a specific census tract.  census tracts/block groups are assigned to address records via a geocoding process.\n",
    "\n",
    "Special value \"0\" - missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CENSUS_BLOCK', count_values=['0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LATITUDE**: Parcel level assigned via point geo coding.  half of a pair of coordinates (the other being longitude)  provided in a formatted value, with decimals or a negative sign. not available in puerto rico & virgin island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('LATITUDE', distribution=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LONGITUDE**: Parcel level assigned via point geo coding.  note: longitudes are negatives values in the western hemisphere.  provided in its formatted value, with decimals or a negative sign. not available in puerto rico & virigin island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('LONGITUDE', distribution=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MATCH_CODE**: Parcel level match code of the business location.  \n",
    "Value labels:  \n",
    "0: Site level  \n",
    "2: Zip+2 centroid  \n",
    "4: Zip+4 centroid  \n",
    "P: Parcel  \n",
    "X: Zip centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('MATCH_CODE', count_values=get_schema('MATCH_CODE')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CBSA_CODE**: Core bases statistical area (expanded msa code)\n",
    "\n",
    "Special value \"00000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CBSA_CODE', count_values=['00000']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CBSA_LEVEL**: Indicates if an area is a micropolitan or metropolitan area  \n",
    "Value labels:  \n",
    "1: Micropolitan  \n",
    "2: Metropolitan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CBSA_LEVEL', count_values=get_schema('CBSA_LEVEL')['enum']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSA_CODE**: Adjoining cbsa's.  combination of metro and micro areas\n",
    "\n",
    "Special value \"000\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('CSA_CODE', count_values=['000']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIPS_CODE**: First 2 bytes = state code, last 3 bytes = county code (location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_output\n",
    "style(describe_variable('FIPS_CODE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonregular variables\n",
    "\n",
    "The following variables are only available in select years.\n",
    "\n",
    "- ...\n",
    "\n",
    "\n",
    "Population code exists for all years, but coding changes after 2015.\n",
    "\n",
    "**POPULATION_CODE**: The code for the resident population of the city in which the business is located, according to rand mcnally. some assignments can vary within a ciyt, such as when cities cross county lines. to maintain this granularity, the actual assignment is done at a zip level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of geographic variables\n",
    "\n",
    "Geographic variables\n",
    "\n",
    "- ADDRESS: historical address\n",
    "- CITY: historical address city\n",
    "- STATE: historical address state\n",
    "- ZIP: historical address zip code\n",
    "- ZIP4: historical address zip code zip + 4\n",
    "- COUNTY_CODE: county code based upon location address/zip4 (postal)\n",
    "- AREA_CODE: area code of business\n",
    "- ADDRESS_TYPE: indicates if type of address. \"F\": \"Firm\", \"G\": \"General delivery\", \"H\": \"High-rise\", \"M\": \"Military\", \"P\": \"Post office box\", \"R\": \"Rural route or hwy contract\", \"S\": \"Street\", \"N\": \"Unknown\", \"\": \"No match to Zip4\".\n",
    "- CENSUS_TRACT: identifies a small geographic area for the purpose of collecting and compiling population and housing data.  census tracts are unique only within census county, and census counties are unique only within census state.  \n",
    "- CENSUS_BLOCK: bgs are subdivisions of census tracts and unique only within a specific census tract.  census tracts/block groups are assigned to address records via a geocoding process.\n",
    "- LATITUDE: parcel level assigned via point geo coding.  half of a pair of coordinates (the other being longitude)  provided in a formatted value, with decimals or a negative sign. not available in puerto rico & virgin island.\n",
    "- LONGITUDE: parcel level assigned via point geo coding.  note: longitudes are negatives values in the western hemisphere.  provided in its formatted value, with decimals or a negative sign. not available in puerto rico & virigin island\n",
    "- MATCH_CODE: parcel level match code of the business location. \"0\": \"Site level\", \"2\": \"Zip+2 centroid\", \"4\": \"Zip+4 centroid\", \"P\": \"Parcel\", \"X\": \"Zip centroid\".\n",
    "- CBSA_CODE: core bases statistical area (expanded msa code)\n",
    "- CBSA_LEVEL: indicates if an area is a micropolitan or metropolitan area. \"1\": \"Micropolitan\", \"2\": \"Metropolitan\"\n",
    "- CSA_CODE: adjoining cbsa's.  combination of metro and micro areas\n",
    "- FIPS_CODE: first 2 bytes = state code, last 3 bytes = county code (location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = ['ADDRESS', 'CITY', 'STATE', 'ZIP', 'ZIP4', 'COUNTY_CODE', 'AREA_CODE', 'ADDRESS_TYPE', \n",
    "            'CENSUS_TRACT', 'CENSUS_BLOCK', 'LATITUDE', 'LONGITUDE', 'MATCH_CODE', \n",
    "            'CBSA_CODE', 'CBSA_LEVEL', 'CSA_CODE', 'FIPS_CODE']\n",
    "total_count = {}\n",
    "isna_count = {}\n",
    "other_count = {}\n",
    "\n",
    "for year in range(1997, 2018):\n",
    "    df = get_df(year, cols=geo_cols)\n",
    "\n",
    "    total_count[year] = len(df)\n",
    "\n",
    "    isna_count[year] = {}\n",
    "    for col in geo_cols:\n",
    "        isna_count[year][col] = df[col].isna().sum()\n",
    "\n",
    "    other_count[year] = {}\n",
    "    other_count[year]['ADDRESS_TYPE'] = (df['ADDRESS_TYPE'] == 'N').sum()\n",
    "    other_count[year]['CENSUS_TRACT'] = (df['CENSUS_TRACT'] == '000000').sum() # is 000000 a valid tract id?\n",
    "    other_count[year]['CENSUS_BLOCK'] = (df['CENSUS_BLOCK'] == '0').sum() # is 0 a valid block id?\n",
    "    other_count[year]['CBSA_CODE'] = (df['CBSA_CODE'] == '00000').sum()\n",
    "    other_count[year]['CSA_CODE'] = (df['CSA_CODE'] == '000').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATE, COUNTY_CODE and FIPS_CODE\n",
    "\n",
    "- STATE is never missing\n",
    "- Tiny fraction (0.0001%) have missing COUNTY_CODE or FIPS_CODE\n",
    "- Until 2012, about 2% have inconsistent codes, and only a few after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fips_map = {\n",
    "'AL':'01',\n",
    "'AK':'02',\n",
    "'AS':'60',\n",
    "'AZ':'04',\n",
    "'AR':'05',\n",
    "'CA':'06',\n",
    "'CO':'08',\n",
    "'CT':'09',\n",
    "'DE':'10',\n",
    "'DC':'11',\n",
    "'FL':'12',\n",
    "'FM':'64',\n",
    "'GA':'13',\n",
    "'GU':'66',\n",
    "'HI':'15',\n",
    "'ID':'16',\n",
    "'IL':'17',\n",
    "'IN':'18',\n",
    "'IA':'19',\n",
    "'KS':'20',\n",
    "'KY':'21',\n",
    "'LA':'22',\n",
    "'ME':'23',\n",
    "'MH':'68',\n",
    "'MD':'24',\n",
    "'MA':'25',\n",
    "'MI':'26',\n",
    "'MN':'27',\n",
    "'MS':'28',\n",
    "'MO':'29',\n",
    "'MT':'30',\n",
    "'NE':'31',\n",
    "'NV':'32',\n",
    "'NH':'33',\n",
    "'NJ':'34',\n",
    "'NM':'35',\n",
    "'NY':'36',\n",
    "'NC':'37',\n",
    "'ND':'38',\n",
    "'MP':'69',\n",
    "'OH':'39',\n",
    "'OK':'40',\n",
    "'OR':'41',\n",
    "'PW':'70',\n",
    "'PA':'42',\n",
    "'PR':'72',\n",
    "'RI':'44',\n",
    "'SC':'45',\n",
    "'SD':'46',\n",
    "'TN':'47',\n",
    "'TX':'48',\n",
    "'UM':'74',\n",
    "'UT':'49',\n",
    "'VT':'50',\n",
    "'VA':'51',\n",
    "'VI':'78',\n",
    "'WA':'53',\n",
    "'WV':'54',\n",
    "'WI':'55',\n",
    "'WY':'56'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=resources.paths['root']/'tmp/geo_valid.log', level=logging.INFO, format='%(message)s', force=True)\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(message)s', force=True)\n",
    "crosstabs = {}\n",
    "for year in range(1997, 2018):\n",
    "    df = get_df(year, cols=['STATE', 'COUNTY_CODE', 'FIPS_CODE'])\n",
    "\n",
    "    df['_STATE_CODE'] = df['STATE'].map(state_fips_map, 'ignore')\n",
    "    state_isna = df['STATE'].isna()\n",
    "    state_isna.name = 'STATE is NA'\n",
    "    county_isna = df['COUNTY_CODE'].isna()\n",
    "    county_isna.name = 'COUNTY_CODE is NA'\n",
    "    fips_isna = df.FIPS_CODE.isna()\n",
    "    fips_isna.name = 'FIPS_CODE is NA'\n",
    "    county_eq_fips = (df['COUNTY_CODE'] == df['FIPS_CODE'].str[2:])\n",
    "    county_eq_fips.name = 'COUNTY_CODE consistent with FIPS_CODE'\n",
    "    state_eq_fips = (df['_STATE_CODE'] == df['FIPS_CODE'].str[:2])\n",
    "    state_eq_fips.name = 'STATE consistent with FIPS_CODE'\n",
    "\n",
    "    crosstab = pd.crosstab([state_isna, county_isna, fips_isna], [county_eq_fips, state_eq_fips])\n",
    "    crosstabs[year] = crosstab.stack([0, 1])\n",
    "    logging.info(f'''\n",
    "    ---- {year} ----\n",
    "    STATE, COUNTY_CODE and FIPS_CODE consistency\n",
    "\n",
    "    {crosstab}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.concat(crosstabs).unstack(0).fillna(0).astype(int).T\n",
    "ct = ct.loc[:, ~(ct == 0).all()].droplevel(0, 1)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = pd.DataFrame()\n",
    "ctf['Valid'] = ct.loc[:, (False, False, True, True)]\n",
    "ctf['Missing COUNTY_CODE or FIPS_CODE'] = ct[True].sum(1) + ct[(False, True,)].iloc[:, 0]\n",
    "ctf['Inconsistent codes'] = ct.sum(1) - ctf.sum(1)\n",
    "pd.testing.assert_series_equal(ct.sum(1), ctf.sum(1))\n",
    "ctf.loc['Total', :] = ctf.sum()\n",
    "ctf['Total'] = ctf.sum(1)\n",
    "ctf = ctf.astype(int)\n",
    "ctf.style.format('{:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctfr = ctf.copy()\n",
    "for c in ctfr:\n",
    "    ctfr[c] /= ctfr['Total']\n",
    "ctfr.style.format('{:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBSA_CODE and CBSA_LEVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
