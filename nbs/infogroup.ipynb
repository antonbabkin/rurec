{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGroup data\n",
    "\n",
    "> Process and prepare InfoGroup dataset.\n",
    "\n",
    "## Processing\n",
    "\n",
    "Starting from original CSV files.\n",
    "\n",
    "- Convert to unicode\n",
    "- Validate against JSON schema. A few erroneous data entries are erased here (e.g. text in numerical column). Existing implementation uses datapackage validator and takes several days with single core.\n",
    "- Save to disk in parquet format.\n",
    "- Provide interface to load single year of data. Allow filtering, column selection and small (optionally random) sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp infogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "from IPython import display\n",
    "\n",
    "from rurec import resources\n",
    "from rurec.resources import Resource\n",
    "from rurec import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(1997, 2018):\n",
    "    resources.add(Resource(f'infogroup/csv/{y}', f'/InfoGroup/data/processed/{y}.csv', f'Processed InfoGroup data, {y}, CSV format', False))\n",
    "    resources.add(Resource(f'infogroup/schema/{y}', f'/InfoGroup/data/processed/{y}_schema.json', f'Processed InfoGroup data, {y}, schema', False))\n",
    "    resources.add(Resource(f'infogroup/pq/{y}', f'/InfoGroup/data/processed/{y}.pq', f'Processed InfoGroup data, {y}, parquet format', False))\n",
    "    resources.add(Resource(f'infogroup/orig/{y}', f'/InfoGroup/data/original/raw/{y}_Business_Academic_QCQ.csv', f'Original unprocessed InfoGroup data, {y}', False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear and validate raw data\n",
    "\n",
    "- Change \"latin-1\" encoding to \"utf-8\", remove double quotes around values.\n",
    "- Remove double quotes around every value.\n",
    "- Rename columns to ALL_CAPS.\n",
    "- Correct 2-digit state part of the FIPS code.\n",
    "- Correct missing CBSA code and CBSA level, mainly in 2009.\n",
    "- In 2009: pad string fields with zeroes.\n",
    "- Validate values format, replace errors with missing values.\n",
    "\n",
    "\n",
    "### Validate values in columns\n",
    "\n",
    "Check when values do not satisfy given constraints, fill with missing and report in a log.\n",
    "\n",
    "Constraints:\n",
    "- STATE: enum\n",
    "- ZIP: 5 digits\n",
    "- ZIP4: 4 digits\n",
    "- COUNTY_CODE: 3 digits, equals to last 3 digits of FIPS_CODE\n",
    "- AREA_CODE: 3 digits\n",
    "- ID_CODE: enum\n",
    "- SIC, SIC0-SIC4: 6 digits\n",
    "- NAICS: 8 digits\n",
    "- YEAR: equals data file year\n",
    "- YP_CODE: 5 digits\n",
    "- EMPLOYEES, SALES, PARENT_EMPLOYEES, PARENT_SALES: non-negative integer\n",
    "- EMPLOYEES_CODE, SALES_CODE, PARENT_EMPLOYEES_CODE, PARENT_SALES_CODE: enum\n",
    "- BUSINESS_STATUS: enum\n",
    "- YEAR_EST: > 1700, <= YEAR\n",
    "- OFFICE_SIZE_CODE: enum\n",
    "- HOLDING_STATUS: enum\n",
    "- ABI: unique, notnull, 9 digits\n",
    "- SUBSIDIARY_NUMBER: 9 digits\n",
    "- PARENT_NUMBER: 9 digits\n",
    "- SITE_NUMBER: 9 digits\n",
    "- ADDRESS_TYPE: enum\n",
    "- POPULATION_CODE: enum\n",
    "- CENSUS_TRACT: 6 digits\n",
    "- CENSUS_BLOCK: 1 digit\n",
    "- LATITUDE, LONGITUDE: float, within US bounding box\n",
    "- MATCH_CODE: enum\n",
    "- CBSA_CODE: 5 digits\n",
    "- CBSA_LEVEL: enum\n",
    "- CSA_CODE: 3 digits\n",
    "- FIPS_CODE: 5 digits\n",
    "\n",
    "\n",
    "\n",
    "Potential additional validations:\n",
    "- codes as enums (SIC, NAICS, FIPS, ...)\n",
    "- CBSA_LEVEL consistent with CBSA_CODE\n",
    "- geo variable consistency: lon-lat, nesting of areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some variables categories are known in advance: states, size codes etc.\n",
    "\n",
    "For others, such as city, zip or NAICS it might be benefitial to use categoricals for performance, but if list of categories is taken from data, it might change year to year. If done, this should be done carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def validate_raw_strings(df):\n",
    "    \"\"\"Validate values in raw InfoGroup data according to string constraints.\n",
    "    Return list of dicts of invalid values.\n",
    "    \"\"\"\n",
    "    \n",
    "    constraints = {\n",
    "        'STATE': {'cats': ['AK','AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','HI','IA',\n",
    "                           'ID','IL','IN','KS','KY','LA','MA','MD','ME','MI','MN','MO','MS',\n",
    "                           'MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH','OK','OR','PA',\n",
    "                           'PR','RI','SC','SD','TN','TX','UT','VA','VI','VT','WA','WI','WV','WY']},\n",
    "        'ZIP': {'number': True, 'nchar': 5},\n",
    "        'ZIP4': {'number': True, 'nchar': 4},\n",
    "        'COUNTY_CODE': {'number': True, 'nchar': 3},\n",
    "        'AREA_CODE': {'number': True, 'nchar': 3},\n",
    "        'ID_CODE': {'cats': ['1', '2']},\n",
    "        'SIC': {'number': True, 'nchar': 6},\n",
    "        'SIC0': {'number': True, 'nchar': 6},\n",
    "        'SIC1': {'number': True, 'nchar': 6},\n",
    "        'SIC2': {'number': True, 'nchar': 6},\n",
    "        'SIC3': {'number': True, 'nchar': 6},\n",
    "        'SIC4': {'number': True, 'nchar': 6},\n",
    "        'NAICS': {'number': True, 'nchar': 8},\n",
    "        'YEAR': {'notna': True, 'number': True},\n",
    "        'YP_CODE': {'number': True, 'nchar': 5},\n",
    "        'EMPLOYEES': {'number': True},\n",
    "        'SALES': {'number': True},\n",
    "        'PARENT_EMPLOYEES': {'number': True},\n",
    "        'PARENT_SALES': {'number': True},\n",
    "        'EMPLOYEES_CODE': {'cats': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']},\n",
    "        'SALES_CODE': {'cats': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']},\n",
    "        'PARENT_EMPLOYEES_CODE': {'cats': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']},\n",
    "        'PARENT_SALES_CODE': {'cats': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']},\n",
    "        'BUSINESS_STATUS': {'cats': ['1', '2', '3', '9']},\n",
    "        'YEAR_EST': {'number': True},\n",
    "        'OFFICE_SIZE_CODE': {'cats': ['A', 'B', 'C', 'D', 'E', 'F']},\n",
    "        'HOLDING_STATUS': {'cats': ['0', '1', '2']},\n",
    "        'ABI': {'unique': True, 'notna': True, 'number': True, 'nchar': 9},\n",
    "        'SUBSIDIARY_NUMBER': {'number': True, 'nchar': 9},\n",
    "        'PARENT_NUMBER': {'number': True, 'nchar': 9},\n",
    "        'SITE_NUMBER': {'number': True, 'nchar': 9},\n",
    "        'ADDRESS_TYPE': {'cats': ['F', 'G', 'H', 'M', 'P', 'R', 'S', 'N']},\n",
    "        'POPULATION_CODE': {'cats': ['1', '5', '6', '7', '8', '9']},\n",
    "        'CENSUS_TRACT': {'number': True, 'nchar': 6},\n",
    "        'CENSUS_BLOCK': {'number': True, 'nchar': 1},\n",
    "        'LATITUDE': {'number': True},\n",
    "        'LONGITUDE': {'number': True},\n",
    "        'MATCH_CODE': {'cats': ['0', '2', '4', 'P', 'X']},\n",
    "        'CBSA_CODE': {'number': True, 'nchar': 5},\n",
    "        'CBSA_LEVEL': {'cats': ['1', '2']},\n",
    "        'CSA_CODE': {'number': True, 'nchar': 3},\n",
    "        'FIPS_CODE': {'number': True, 'nchar': 5}\n",
    "    }\n",
    "    return util.validate_values(df, constraints)\n",
    "\n",
    "\n",
    "def convert_dtypes(df):\n",
    "    \"\"\"Inplace convert string columns to appropriate types.\"\"\"\n",
    "    \n",
    "    for col in ['YEAR', 'EMPLOYEES', 'SALES', 'PARENT_EMPLOYEES', 'PARENT_SALES', 'YEAR_EST', 'LATITUDE', 'LONGITUDE']:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "        \n",
    "    cat_cols = {\n",
    "        'STATE': ['AK','AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','HI','IA',\n",
    "                   'ID','IL','IN','KS','KY','LA','MA','MD','ME','MI','MN','MO','MS',\n",
    "                   'MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH','OK','OR','PA',\n",
    "                   'PR','RI','SC','SD','TN','TX','UT','VA','VI','VT','WA','WI','WV','WY'],\n",
    "        'ID_CODE': ['1', '2'],\n",
    "        'EMPLOYEES_CODE': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'],\n",
    "        'SALES_CODE': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'],\n",
    "        'PARENT_EMPLOYEES_CODE': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'],\n",
    "        'PARENT_SALES_CODE': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'],\n",
    "        'BUSINESS_STATUS': ['1', '2', '3', '9'],\n",
    "        'OFFICE_SIZE_CODE': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
    "        'HOLDING_STATUS': ['0', '1', '2'],\n",
    "        'ADDRESS_TYPE': ['F', 'G', 'H', 'M', 'P', 'R', 'S', 'N'],\n",
    "        'POPULATION_CODE': ['1', '5', '6', '7', '8', '9'],\n",
    "        'MATCH_CODE': ['0', '2', '4', 'P', 'X'],\n",
    "        'CBSA_LEVEL': ['1', '2']\n",
    "    }\n",
    "        \n",
    "    for col, cats in cat_cols.items():\n",
    "        df[col] = pd.Categorical(df[col], categories=cats)\n",
    "\n",
    "\n",
    "def validate_raw_numbers(df):\n",
    "    \"\"\"Validate values in raw InfoGroup data according to numerical constraints.\n",
    "    Return list of dicts of invalid values.\n",
    "    \"\"\"\n",
    "    \n",
    "    constraints = {\n",
    "        'YEAR': {'eq': year},\n",
    "        'EMPLOYEES': {'ge': 0},\n",
    "        'SALES': {'ge': 0},\n",
    "        'PARENT_EMPLOYEES': {'ge': 0},\n",
    "        'PARENT_SALES': {'ge': 0},\n",
    "        'YEAR_EST': {'ge': 1500, 'le': year},\n",
    "        'LATITUDE': {'ge': 0, 'le': 90},\n",
    "        'LONGITUDE': {'ge': -180, 'le': 0}\n",
    "    }\n",
    "    return util.validate_values(df, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2011\n",
    "sch = json.load(resources.get(f'infogroup/schema/{year}').path.open())\n",
    "df = pd.read_csv(resources.get(f'infogroup/orig/{year}').path, dtype='str', encoding='latin-1')\n",
    "\n",
    "df.rename(columns={x['originalName']: x['name'].upper() for x in sch['fields']}, inplace=True)\n",
    "\n",
    "invalid_values = validate_raw_strings(df)\n",
    "convert_dtypes(df)\n",
    "invalid_values += validate_raw_numbers(df)\n",
    "\n",
    "df.to_csv(resources.get(f'infogroup/csv/{year}').path, index=False)\n",
    "fastparquet.write(resources.get(f'infogroup/pq/{year}').path, df, write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_df(year, cols=None):\n",
    "    \"\"\"Return one year of InfoGroup data with appropriate data types.\n",
    "    Subset of columns can be loaded by passing list to `cols`.\n",
    "    \"\"\"\n",
    "    res = resources.get(f'infogroup/pq/{year}')\n",
    "    return pd.read_parquet(res.path, 'fastparquet', columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infogroup: county_code == fips_code[2:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
