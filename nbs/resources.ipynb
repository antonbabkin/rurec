{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource management\n",
    "\n",
    "> Manage project resources such as data and images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module serves two main purposes.\n",
    "- Consolidate paths to resources used across project modules.\n",
    "- Provide methods to sync resources between local and remote storage locations.\n",
    "\n",
    "Main parts of the interface, available in module namespace (`import resouces`):\n",
    "- `paths` dict: paths to project root and remote data repo.\n",
    "- `Resouce` class: representation of a single file resouce.\n",
    "- `add`, `get` and `remove` functions: interact with default resouce registry.\n",
    "\n",
    "Resources are either synced or not. \"Sync\" resouce has local and remote paths and can be sent both ways. \"Non-sync\" resource has only single path.\n",
    "\n",
    "Registered resources are added to a JSON registry file (`resources.json` in project root by default), which is intended to be version controlled by Git.\n",
    "\n",
    "### Example 1. Refer to file and directory paths\n",
    "\n",
    "To support portability, use absolute paths defined relative to `paths['root']`. It is encouraged to use `pathlib.Path` objects.\n",
    "\n",
    "```python\n",
    "temp_table_path = resources.paths['root'] / 'tmp/tab.csv'\n",
    "temp_table = pd.read_csv(temp_table_path)\n",
    "```\n",
    "\n",
    "### Example 2. Read-only use of resource created and registered by others\n",
    "\n",
    "Use `resouces.get()` without arguments to see all resources registered in the project. Pass a key argument to obtain a single resouce or a specific subset.\n",
    "\n",
    "Non-sync resource example.\n",
    "```python\n",
    "raw_data_res = resources.get('raw/table/csv')\n",
    "raw_data_df = pd.read_csv(raw_data_res.path)\n",
    "```\n",
    "\n",
    "Sync resource example.\n",
    "```python\n",
    "proc_data_res = resouces.get('proc/table/csv')\n",
    "proc_data_df = pd.read_csv(proc_data_res.remote_path)\n",
    "```\n",
    "\n",
    "### Example 3. Pull-modify-push sync resource\n",
    "\n",
    "Take something created by others, modify it and share the updated version.\n",
    "\n",
    "```python\n",
    "proc_data_res = resouces.get('proc/table/csv')\n",
    "# get local copy\n",
    "proc_data_res.pull()\n",
    "# modify and save local copy\n",
    "proc_data_df = pd.read_csv(proc_data_res.path)\n",
    "modified = proc_data_df.sort_values()\n",
    "modified.to_csv(proc_data_res.path)\n",
    "# share updated version\n",
    "proc_data_res.push()\n",
    "```\n",
    "\n",
    "### Example 4. Create and register new resource\n",
    "\n",
    "```python\n",
    "fig_res = resources.Resource(key='out/fig', path='output/fig.png', description='Rise and fall')\n",
    "resources.add(fig_res)\n",
    "plt.savefig(fig_res.path)\n",
    "fig_res.push()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tempfile\n",
    "import configparser\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "# it's probably worth organizing this into a Paths class\n",
    "def _get_root_dir():\n",
    "    \"\"\"Return `pathlib.Path` to project root directory.\n",
    "    Root is identified by presence of \"settings.ini\" file.\"\"\"\n",
    "    d = Path.cwd()\n",
    "    while d != d.parent:\n",
    "        if (d / 'settings.ini').exists(): return d\n",
    "        d = d.parent\n",
    "    raise Exception(f'Can not find project root at or above \"{Path.cwd()}\"')\n",
    "    \n",
    "\n",
    "def abs_path(path):\n",
    "    path = Path(path)\n",
    "    if path.is_absolute():\n",
    "        return path\n",
    "    return _get_root_dir() / path\n",
    "\n",
    "\n",
    "def _get_paths_from_config():\n",
    "    root = _get_root_dir()\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(root / 'settings.ini')\n",
    "    paths = dict()\n",
    "    paths['root'] = root\n",
    "    \n",
    "    cache = abs_path(config['resources']['cache_dir'])\n",
    "    cache.mkdir(parents=True, exist_ok=True)\n",
    "    paths['cache'] = cache\n",
    "    \n",
    "    remote = Path(config['resources']['remote_dir'])\n",
    "    assert remote.is_absolute()\n",
    "    assert remote.exists() and remote.is_dir()\n",
    "    paths['remote'] = remote\n",
    "    \n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class Resource:\n",
    "    \"\"\"Abstraction of a single file.\"\"\"\n",
    "    def __init__(self, key, path, description='', sync=True, public=False):\n",
    "        \"\"\"Declare new resource. `key` should be a short name.\n",
    "        Underlying files do not need to exist.\n",
    "        `sync` enabled resources must have relative `path`, \n",
    "        they can be synced between local project directory and remote resource repository.\n",
    "        \"\"\"\n",
    "        self.key = key\n",
    "        self._raw_path = path\n",
    "        self.description = description\n",
    "        self.sync = sync\n",
    "        self.public = public\n",
    "        \n",
    "        path = Path(path)\n",
    "        if sync:\n",
    "            assert not path.is_absolute()\n",
    "            self.path = paths['root'] / path\n",
    "            self.remote_path = paths['remote'] / path\n",
    "        else:\n",
    "            if not path.is_absolute():\n",
    "                path = paths['root'] / path\n",
    "            self.path = path\n",
    "            self.remote_path = None\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return repr(self._to_dict())\n",
    "    \n",
    "    __str__ = __repr__\n",
    "\n",
    "    def _to_dict(self):\n",
    "        return dict(key=self.key, path=self._raw_path, description=self.description, sync=self.sync, public=self.public)\n",
    "    \n",
    "    @classmethod\n",
    "    def _from_dict(cls, d):\n",
    "        return cls(**d)\n",
    "    \n",
    "    def push(self):\n",
    "        \"\"\"Copy sync-enabled resource from local to remote.\"\"\"\n",
    "        if not self.sync: \n",
    "            print(f'Can not push sync-disabled resource \"{self.key}\"')\n",
    "            return\n",
    "        self.remote_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(self.path, self.remote_path)\n",
    "        print(f'Pushed \"{self.key}\": {self.path} -> {self.remote_path}')\n",
    "    \n",
    "    def pull(self):\n",
    "        \"\"\"Copy sync-enabled resource from remote to local.\"\"\"\n",
    "        if not self.sync: \n",
    "            print(f'Can not pull sync-disabled resource \"{self.key}\"')\n",
    "            return\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(self.remote_path, self.path)\n",
    "        print(f'Pulled \"{self.key}\": {self.remote_path} -> {self.path}')\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Remove local copy of sync-enabled resource.\"\"\"\n",
    "        if not self.sync: \n",
    "            print(f'Can not clear sync-disabled resource \"{self.key}\"')\n",
    "            return\n",
    "        self.path.unlink()\n",
    "        print(f'Removed local \"{self.key}\": {self.path}')\n",
    "        \n",
    "    def clear_remote(self):\n",
    "        \"\"\"Remove remote copy of sync-enabled resource.\"\"\"\n",
    "        if not self.sync: \n",
    "            print(f'Can not clear sync-disabled resource \"{self.key}\"')\n",
    "            return\n",
    "        self.remote_path.unlink()\n",
    "        print(f'Removed remote \"{self.key}\": {self.path}')\n",
    "    \n",
    "    def publish(self):\n",
    "        \"\"\"Send resource to public-facing repository.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class Registry:\n",
    "    \"\"\"Registry of resources, synced with file on disk.\"\"\"\n",
    "    def __init__(self, registry_file='resources.json'):\n",
    "        self.file = abs_path(registry_file)\n",
    "\n",
    "        self.resources = dict()\n",
    "        if self.file.exists():\n",
    "            res_dicts = json.load(self.file.open())\n",
    "            for res_dict in res_dicts.values():\n",
    "                res = Resource._from_dict(res_dict)\n",
    "                self.resources[res.key] = res     \n",
    "        else:\n",
    "            self._dump()\n",
    "\n",
    "    def _dump(self):\n",
    "        \"\"\"Save registry to disk.\n",
    "        Records are ordered by key.\"\"\"\n",
    "        # Dicts iterate in the order of key insertions.\n",
    "        # Assuming that json.dump() maintains that ordering.\n",
    "        res_dicts = dict()\n",
    "        for key in sorted(self.resources.keys()):\n",
    "            res_dicts[key] = self.resources[key]._to_dict()\n",
    "        json.dump(res_dicts, self.file.open('w'), indent=2)\n",
    "\n",
    "    def add(self, res, overwrite=False):\n",
    "        \"\"\"Add new resource to registry.\"\"\"\n",
    "        if not overwrite and res.key in self.resources:\n",
    "            print(f'Resource \"{res.key}\" already in the registry, did not overwrite.')\n",
    "            return\n",
    "        if res.key in self.resources:\n",
    "            old_res = self.resources[res.key]\n",
    "            print(f'Overwriting existing resource: {old_res}')\n",
    "        self.resources[res.key] = res\n",
    "        self._dump()\n",
    "        print(f'Resource \"{res.key}\" added to registry.')\n",
    "    \n",
    "    def remove(self, key):\n",
    "        \"\"\"Remove resource with exact `key`.\"\"\"\n",
    "        if key not in self.resources:\n",
    "            print(f'Resource \"{key}\" not found.')\n",
    "            return\n",
    "        del self.resources[key]\n",
    "        self._dump()\n",
    "        print(f'Resource \"{key}\" removed from registry.')\n",
    "    \n",
    "    def get(self, key_pattern='*'):\n",
    "        \"\"\"Return list of resources with key matching glob-like `key_pattern`.\n",
    "        If match is unique, return single resource object.\n",
    "        List is sorted by key.\n",
    "        \"\"\"\n",
    "        matches = [r for k, r in self.resources.items()\n",
    "                   if Path(k).match(key_pattern)]\n",
    "        matches.sort(key=lambda res: res.key)\n",
    "        return matches[0] if len(matches) == 1 else matches\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "paths = _get_paths_from_config()\n",
    "\n",
    "_registry = Registry('resources.json')\n",
    "\n",
    "add = _registry.add\n",
    "get = _registry.get\n",
    "remove = _registry.remove\n",
    "\n",
    "def pull(key_pattern='*'):\n",
    "    \"\"\"Get resources matching `key_pattern` from remote repository.\"\"\"\n",
    "    for r in _registry.get(key_pattern):\n",
    "        if r.sync:\n",
    "            r.pull()\n",
    "\n",
    "def push(key_pattern='*'):\n",
    "    \"\"\"Send resources matching `key_pattern` to remote repository.\"\"\"\n",
    "    for r in _registry.get(key_pattern):\n",
    "        if r.sync:\n",
    "            r.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def _hash(x):\n",
    "    \"\"\"Generalized version of builtin hash() to support some unhashable types.\"\"\"\n",
    "    # Recursive calls allow to hash nested structures.\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(x, (pd.Series, pd.DataFrame)):\n",
    "        # WARNING: only head of the dataframe is hashed, for speed sake\n",
    "        x_head_hash_series = pd.util.hash_pandas_object(x.head())\n",
    "        return hash(tuple(x_head_hash_series))\n",
    "\n",
    "    if isinstance(x, dict):\n",
    "        return _hash(tuple(x.items()))\n",
    "    \n",
    "    try:\n",
    "        return hash(x)\n",
    "    except TypeError:\n",
    "        return hash(tuple(_hash(y) for y in x))\n",
    "        \n",
    "\n",
    "def hash_args(*args, **kwargs):\n",
    "    \"\"\"Return hash of passed arguments.\"\"\"\n",
    "    return _hash(args + tuple(kwargs.items()))\n",
    "\n",
    "def func_sig(fname, *args, **kwargs):\n",
    "    \"\"\"Return string representation of function call signature.\"\"\"\n",
    "    import pandas as pd\n",
    "    def _repr(x):\n",
    "        if isinstance(x, pd.Series):\n",
    "            return f'series({len(x)})'\n",
    "        if isinstance(x, pd.DataFrame):\n",
    "            return f'dataframe{x.shape}'\n",
    "        return repr(x)\n",
    "    \n",
    "    ar = ', '.join(_repr(x) for x in args)\n",
    "    kw = ', '.join(f'{k}: {_repr(v)}' for k, v in kwargs.items())\n",
    "    arkw = ', '.join(x for x in [ar, kw] if x != '')\n",
    "    return f'{fname}({arkw})'\n",
    "\n",
    "def cacheable(func):\n",
    "    \"\"\"Enable caching of function results.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        arghash = hash_args(*args, **kwargs)\n",
    "        fn = func.__name__\n",
    "        sig = func_sig(fn, *args, **kwargs)\n",
    "        cached = paths['cache'] / fn / str(arghash)\n",
    "        \n",
    "        if cached.exists():\n",
    "            modified = datetime.datetime.fromtimestamp(cached.stat().st_mtime).isoformat(' ')\n",
    "            logging.info(f'Return cached result of {sig}, last modified at {modified}')\n",
    "            return pickle.load(cached.open('rb'))\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "        cached.parent.mkdir(exist_ok=True)\n",
    "        pickle.dump(result, cached.open('wb'))\n",
    "        logging.info(f'Result of {sig} cached to {cached}')\n",
    "        return result\n",
    "            \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Convert resource to and from dict.\n",
    "d = dict(key='a/b', path='a/b.csv', description='data B', sync=True, public=True)\n",
    "r = Resource._from_dict(d)\n",
    "assert r._to_dict() == d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Pull synced resource, update content and push back, clean up.\n",
    "r = Resource('test/pull-upd-push', 'tmp/pull-upd-push.txt', 'Test pull-upd-push')\n",
    "r.remote_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "r.remote_path.write_text('Jack')\n",
    "r.pull()\n",
    "assert r.path.read_text() == 'Jack'\n",
    "f = r.path.open('a')\n",
    "f.write(' and Jill')\n",
    "f.close()\n",
    "r.push()\n",
    "assert r.remote_path.read_text() == 'Jack and Jill'\n",
    "r.clear()\n",
    "assert not r.path.exists()\n",
    "r.clear_remote()\n",
    "assert not r.remote_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Add, get and remove resources in registry.\n",
    "r = Registry('test_resources.json')\n",
    "assert r.get() == []\n",
    "r.add(Resource('in/data', 'input/data.csv', 'input data'))\n",
    "r.add(Resource('out/data', 'output/result.csv', 'output data'))\n",
    "assert [x.key for x in r.get()] == ['in/data', 'out/data']\n",
    "assert r.get('out/data').description == 'output data'\n",
    "r.remove('out/data')\n",
    "assert r.get().description == 'input data'\n",
    "r.add(Resource('out/data', 'output/result.csv', 'output data'))\n",
    "r.add(Resource('out/fig', 'output/image.png', 'output figure'))\n",
    "assert [x.key for x in r.get()] == ['in/data', 'out/data', 'out/fig']\n",
    "assert [x.description for x in r.get('*/data')] == ['input data', 'output data']\n",
    "assert [x.description for x in r.get('out/*')] == ['output data', 'output figure']\n",
    "assert r.get('out/???').description == 'output figure'\n",
    "assert r.get('whole/world') == []\n",
    "r.remove('in/data')\n",
    "r.remove('out/data')\n",
    "r.remove('out/fig')\n",
    "assert r.get() == []\n",
    "assert r.file.read_text() == '{}'\n",
    "r.file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: caching\n",
    "hash_args(14, 'hello', None, [1, 'a'], ([1, 2], 3), {'a': 1, 'b': 2}, key1=12, key2='ab')\n",
    "hash_args(pd.Series([1, 'a', None]), pd.DataFrame([[1,2],[3,4]]))\n",
    "\n",
    "@cacheable\n",
    "def quack(who):\n",
    "    \"Who quacks?\"\n",
    "    return f'{who} quacks'\n",
    "\n",
    "quack('he')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
