---
title: "Census of Agriculture imputation"
format:
  html:
    toc: true
    code-fold: true
    code-overflow: wrap
    embed-resources: true
    df-print: paged
---

# top

```{r}
library(tidyverse)
library(tmap)
loadNamespace("tigris")
options(tigris_use_cache = TRUE)

source("R/agcensus.R", local = (agcensus <- new.env()))


```

# Raw data

```{r}
df_raw <- agcensus$farm_sales()
```


### commodity hierarchy

```{r}
#| rows.print: 100
df_raw %>%
  filter(measure == "sale", lv_sp == 0) %>%
  mutate(desc = str_sub(short_desc, 1, -24), value = value / 1000) %>%
  arrange(id) %>%
  select(lv_co, commodity, desc, value)
```

### % missing

```{r}
#| rows.print: 100
df_raw %>%
  filter(measure == "sale", lv_sp %in% c(0, 2)) %>%
  summarize(n = n(), nna = sum(!is.na(value)), sale = sum(value / 1000, na.rm = TRUE), .by = c("commodity", "lv_sp")) %>%
  pivot_wider(id_cols = commodity, names_from = lv_sp, values_from = c(n, nna, sale)) %>%
  select(commodity, nat_n = n_2, nat_sale = sale_0, cty_n = nna_2, cty_sale = sale_2) %>%
  mutate(
    pct_na_n = round(1 - cty_n / nat_n, 3) * 100,
    pct_na_sale = round(1 - cty_sale / nat_sale, 3) * 100
  ) %>%
  relocate(commodity, ends_with("_n"), ends_with("sale"))
```

### milk map


```{r}

tigris::counties(cb = TRUE, resolution = "20m", year = 2013) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) %>%
  inner_join(
    df_raw %>% filter(measure == "nsal", commodity == "2a_3mi", lv_sp == 2),
    join_by(STATEFP == id_sp1, COUNTYFP == id_sp2)
  ) %>%
  tm_shape() +
  tm_polygons(
    "value", 
    fill.scale = tm_scale_intervals(
      style = "quantile", 
      label.format = scales::label_number(scale_cut = scales::cut_short_scale())
    ),
    fill.legend = tm_legend(
      title = "",
      orientation = "landscape",
      frame = FALSE
  )) +
  tm_layout(frame = FALSE) +
  tm_title("Milk: Farms")

tigris::counties(cb = TRUE, resolution = "20m", year = 2013) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) %>%
  inner_join(
    df_raw %>% filter(measure == "sale", commodity == "2a_3mi", lv_sp == 2),
    join_by(STATEFP == id_sp1, COUNTYFP == id_sp2)
  ) %>%
  mutate(value = value * 1000) %>%
  tm_shape() +
  tm_polygons(
    "value", 
    fill.scale = tm_scale_intervals(
      style = "quantile", 
      label.format = scales::label_currency(scale_cut = scales::cut_short_scale())
    ),
    fill.legend = tm_legend(
      title = "",
      orientation = "landscape",
      frame = FALSE
  )) +
  tm_layout(frame = FALSE) +
  tm_title("Milk: Sales")

```

# Imputation algorithm

## Raw source data

```{r}
df_raw <- agcensus$farm_sales()
df_raw %>%
  select(id_sp, id_co, measure, value, short_desc) %>%
  head()
```

## Constraints

```{r}
df_con <- df_raw %>%
  filter(measure == "sale") %>%
  agcensus$constraints()
df_con %>%
  select(id_con, id_par, id, value_bal) %>%
  head()
```

`id` identifies a variable to be imputed.
`id_par` identifies a parent variable that children add up to.
Thus each constraint is identified by the corresponding parent variable.
`id_con` identifies constraint type - hierarchy and level.
It distinguishes cases when a variable is a parent for two constrains of spatial and commodity hierarchy.

```{r}
df_con %>%
  mutate(sid = paste(if_else(id == id_par, "-", "+"), id)) %>%
  summarize(lhs = paste(sid, collapse = " "), rhs = first(value_bal), .by = c(id_con, id_par)) %>%
  head()
```

Problem size: number of constraints and variables.

```{r}
df_con %>%
  summarize(n_con = n_distinct(id_par), n_var = n_distinct(id))
```


Constraints can be grouped into subsets of equations sharing common variables.
This allows to reduce problem size for easier computation.

```{r}
df_con %>%
  summarize(n_con = n_distinct(id_par), n_var = n_distinct(id), .by = group) %>%
  arrange(group)
```


## Priors

Priors are based on geographic balances, proportional to number of farms in each child region with missing sales.
This is based on an assumption that average sales per farm are the same across all child regions with missing values for a given commodity.

Commodity balances could also be used, but they would rely on a seemingly stronger assumption that average sales per farm are the same for all child commodities with missing values for a given region.
Additional issue is that multiple farm can produce multiple child commodities.
This is not a problem for geographic balances, since each farm can only be in one child region.

If state value is known, priors can be calculated as in national balances.
If state value is missing, we can not apply same calculation, because unallocated balance is unknown.
We can not use state prior from the national balances, because it could be less than sum of known child county values.
Instead, we make another assumption that average sales per farm in missing counties is the same as average sales per farm in observed counties.

Possibilities:
- parent value known
- parent value unknown, some children known
- parent value unknown, children values unknown

```{r}
df_pri <- agcensus$priors(df_raw)
df_pri %>%
  select(id_sp, id_co, nsal, starts_with("prior"))
```


## Solution

```{r}
gr = 46
d_con <- df_con %>% filter(group == gr)
d_pri <- df_pri %>% filter(id %in% d_con$id)
sol <- agcensus$solve_group(d_con, d_pri)
cbind(sol$mats$amat, bvec = sol$mats$bvec, slack = sol$sols)
d_pri %>%
  left_join(sol$solv %>% as_tibble(rownames = "id"), "id") %>%
  mutate(across(c(prior, value), \(x) round(x / 1000, 1))) %>%
  select(id_sp, id_co, nsal, prior, sol = value) %>%
  arrange(id_sp, id_co)

```







# BEA commodity classification

Comparing total sales before and after imputation.

```{r}
source("R/dataprep_agcensus.R", local = (agcen <- new.env()))

df <- full_join(
  agcen$call_agoutput_old(2012, "county") %>%
    pivot_longer(!place, names_to = "commodity", values_to = "old"),
  agcen$call_agoutput(2012, "county") %>%
    pivot_longer(!place, names_to = "commodity", values_to = "new"),
  c("place", "commodity")
)

df %>%
  summarize(across(c(old, new), sum), .by = "place") %>%
  mutate(
    new_old = if_else(is.na(old), Inf, new / old),
    new_old_bin = cut(new_old, breaks = c(0, 0.5, 0.99, 1.01, 1.5, 100, Inf))
  ) %>%
  count(new_old_bin)
  
```


# Future work

- Impute years besides 2012.
- Review solved slack variables.
- Do a more systematic review of constraints feasibility.
Some adding-up constraints were found to not hold in the raw data.
This information can be included in the optimization problem to ease the pressure on slack variables.
- Explore alternative solvers or penalty functions to avoid zero corner solutions.

# ==== ARCHIVE ====


```{r}
library(tidyverse)
library(arrow)


venn <- function(x, y) {
  and <- base::intersect(x, y)
  or <- base::union(x, y)
  list(
    x = x,
    y = y,
    and = and,
    or = or,
    x_y = base::setdiff(x, y),
    y_x = base::setdiff(y, x),
    xor = base::setdiff(or, and)
  )
}

```

# raw data

```{r}

agcensus_dataset <- function(year) {
  Sys.getenv("PUBDATAPY_DIR") %>%
    file.path("agcensus/agcensus.parquet", year, "part.pq") %>%
    open_dataset() %>%
    rename_with(str_to_lower)
}


```


## suppression flags

```
The following abbreviations and symbols are used throughout the tables: 
- 	Represents zero. 
(D) 	Withheld to avoid disclosing data for individual farms. 
(H) 	Coefficient of variation is greater than or equal to 99.95 percent or the 
standard error is greater than or equal to 99.95 percent of mean. 
(IC) 	Independent city. 
(L) 	Coefficient of variation is less than 0.05 percent or the standard error 
is less than 0.05 percent of the mean. 
(NA) 	Not available. 
(X) 	Not applicable. 
(Z) 	Less than half of the unit shown.
```

## search

```{r}
agcensus_dataset(2012)

agcensus_dataset(2012) %>%
  filter(str_detect(short_desc, "COMMO.*OPER.*SALE")) %>%
  distinct(short_desc) %>%
  collect()

agcensus_dataset(2012) %>%
  distinct(agg_level_desc) %>%
  collect()
```



# filtered data

```{r}

farm_sales <- function() {
  year <- 2012
  
  renames <- tribble(
    ~name,            ~short_desc,
    "nsale_tot",      "COMMODITY TOTALS - OPERATIONS WITH SALES",
    "nsale_crop",     "CROP TOTALS - OPERATIONS WITH SALES",
    "nsale_anim",     "ANIMAL TOTALS, INCL PRODUCTS - OPERATIONS WITH SALES",
    "sale_tot",       "COMMODITY TOTALS - SALES, MEASURED IN $",
    "sale_crop",      "CROP TOTALS - SALES, MEASURED IN $",
    "sale_anim",      "ANIMAL TOTALS, INCL PRODUCTS - SALES, MEASURED IN $",
  )
  
  agcensus_dataset(year) %>%
    filter(agg_level_desc %in% c("NATIONAL", "STATE", "COUNTY"), domain_desc == "TOTAL", short_desc %in% renames$short_desc) %>%
    mutate(stcty = paste0(state_fips_code, if_else(is.na(county_code), "000", county_code))) %>%
    select(state_alpha, county_name, stcty, short_desc, value, value_f) %>%
    collect() %>%
    left_join(renames, "short_desc") %>%
    separate_wider_delim(name, delim = "_", names = c("measure", "commodity"), cols_remove = FALSE) %>%
    mutate(value = if_else(measure == "sale", value / 1000, value)) %>%
    arrange(stcty)
}


```


## never missing at state level

```{r}
x1 <- farm_sales() %>%
  filter(is.na(county_name)) %>%
  pivot_wider(id_cols = c(state_alpha, stcty))

x1[apply(is.na(x1), 1, any), ]

x1
```

## how many counties are missing by state and measure?

```{r}


df_na_summary <- inner_join(
  # state sales
  farm_sales() %>%
    filter(state_alpha != "US", is.na(county_name), measure == "sale") %>%
    select(state_alpha, commodity, sale_st = value),
  # number of reporting counties in state
  farm_sales() %>%
    filter(state_alpha != "US", !is.na(county_name), name == "nsale_tot") %>%
    summarize(n_st = n(), .by = "state_alpha"),
  by = "state_alpha"
) %>%
  inner_join(
    farm_sales() %>%
      filter(state_alpha != "US", !is.na(county_name), measure == "sale") %>%
      summarize(
        n_cty = sum(!is.na(value)),
        sale_cty = sum(value, na.rm = TRUE),
        .by = c(state_alpha, commodity)
      ),
    by = c("state_alpha", "commodity")
  ) %>%
  mutate(n_pct = 100 * n_cty / n_st,
         sale_pct = 100 * sale_cty / sale_st)

df_na_summary

```

### examples to try


```{r}
df_na_summary %>% filter(state_alpha == "DE")

df_na_summary %>%
  filter(state_alpha %in% (df_na_summary %>% filter(commodity == "tot", n_st == n_cty) %>% pull(state_alpha))) %>%
  mutate(avg_pct = mean(n_pct), .by = "state_alpha") %>%
  arrange(avg_pct, commodity)
```



# Imputation algorithm

First experimental implementation with some of the constraints, but not all.

## step 1: isolate single problem


```{r}
df_1 <- farm_sales() %>%
  # filter(state_alpha == "DE") %>%
  filter(state_alpha == "AZ") %>%
  select(sp_id = stcty, co_id = commodity, measure, value) %>%
  mutate(sp_par = str_ends(sp_id, "000"), co_par = (co_id == "tot"), var = paste0(sp_id, "_", co_id))

df_1
```


## step 2: remove known child values from parent totals


```{r}
df_2 <- df_1 %>%
  filter(measure == "sale") %>%
  # unallocated balance within each spatial child unit
  mutate(
    sp_tot = first(if_else(co_par, value, NA), na_rm = TRUE),
    sp_sum = sum(if_else(!co_par, value, NA), na.rm = TRUE),
    sp_bal = sp_tot - sp_sum,
    .by = sp_id
  ) %>%
  # unallocated balance within each commodity child unit
  mutate(
    co_tot = first(if_else(sp_par, value, NA), na_rm = TRUE),
    co_sum = sum(if_else(!sp_par, value, NA), na.rm = TRUE),
    co_bal = co_tot - co_sum,
    .by = co_id
  ) %>%
  # missing values to impute
  filter(is.na(value)) %>%
  select(var, sp_id, co_id, sp_bal, co_bal)

df_2

df_2 %>%
  mutate(sp_bal = paste0("sp=", sp_bal), co_bal = paste0("co=", co_bal)) %>%
  pivot_wider(id_cols = sp_bal, names_from = co_bal, values_from = var)
```


## step 3: QP problem


```{r}

# variables
var_sol <- df_2 %>% pull(var)
var_slk <- c(
  paste0("slk_", df_2 %>% distinct(sp_id) %>% pull()),
  paste0("slk_", df_2 %>% distinct(co_id) %>% pull())
)

# objective fn
## priors
prior <- df_1 %>%
  filter(measure == "nsale") %>%
  select(sp_id, co_id, n = value) %>%
  right_join(df_2, by = c("sp_id", "co_id")) %>%
  mutate(pri = n / sum(n) * co_bal, .by = co_id) %>%
  pull(pri, name = var)
prior <- prior[var_sol]
dvec <- c(1 / prior, rep(0, length(var_slk)))
names(dvec) <- c(var_sol, var_slk)
Dmat <- diag(c(1 / prior**2, rep(1, length(var_slk))))
rownames(Dmat) <- colnames(Dmat) <- names(dvec)

# constraints: spatial
A_sp <- df_2 %>%
  pivot_wider(id_cols = var, names_from = sp_id, values_from = sp_id) %>%
  column_to_rownames("var") %>%
  as.matrix() %>%
  {!is.na(.)} %>%
  `storage.mode<-`("integer")
b_sp <- df_2 %>%
  distinct(sp_id, .keep_all = TRUE) %>%
  pull(sp_bal, name = sp_id)

# constraints: commodity
A_co <- df_2 %>%
  pivot_wider(id_cols = var, names_from = co_id, values_from = co_id) %>%
  column_to_rownames("var") %>%
  as.matrix() %>%
  {!is.na(.)} %>%
  `storage.mode<-`("integer")
b_co <- df_2 %>%
  distinct(co_id, .keep_all = TRUE) %>%
  pull(co_bal, name = co_id)

bvec <- c(b_sp, b_co)
Amat <- cbind(A_sp, A_co)
Amat <- Amat[var_sol, ]

# constraints: add slack
## verify alignment
stopifnot(all(paste0("slk_", colnames(Amat)) == var_slk))
A_slk <- diag(nrow = ncol(Amat), ncol = ncol(Amat))
rownames(A_slk) <- var_slk
Amat <- rbind(Amat, A_slk)

# constraints: non-negativity
Amat <- rbind(
  diag(1, nrow = length(var_sol), ncol = length(var_sol)),
  matrix(0, nrow = length(var_slk), ncol = length(var_sol))
) %>%
  `colnames<-`(paste0(var_sol, "_gt0")) %>%
  cbind(Amat, .)
bvec <- c(bvec, rep(0, length(var_sol)))

cat("---- dvec\n")
dvec[1:length(var_sol)]
cat("---- Amat/bvec equality\n")
rbind(Amat, bvec)

sol_qp <- quadprog::solve.QP(Dmat, dvec, Amat, bvec, meq = length(var_slk))

sol_slk <- sol_qp$solution[length(var_sol) + 1:length(var_slk)]
names(sol_slk) <- var_slk
cat("---- Slack\n")
sol_slk


cat("---- Prior\n")
prior %>%
  as_tibble(rownames = "name") %>%
  separate_wider_delim(name, "_", names = c("stcty", "name")) %>%
  pivot_wider(id_cols = "stcty") %>%
  column_to_rownames("stcty") %>%
  as.matrix() %>%
  round()

cat("---- Solution\n")
tibble(name = var_sol, value = sol_qp$solution[1:length(var_sol)]) %>%
  separate_wider_delim(name, "_", names = c("stcty", "name")) %>%
  pivot_wider(id_cols = "stcty") %>%
  column_to_rownames("stcty") %>%
  as.matrix() %>%
  round()
```


# Other solvers

Allowing for non-quadratic penalty functions.
No slack variables.


```{r}
nx = length(var_sol)
nc = length(var_slk)

# same as QP, without the slack
fn_qp <- function(x) {
  (0.5 * x %*% Dmat[1:nx, 1:nx] %*% x - dvec[1:nx] %*% x)[1]
}

# same as QP 
fn_qp1 <- function(x) {
  sum(((x - prior) / prior) ** 2)
}

# midpoint quadratic deviation
fn_mid <- function(x) {
  dif <- (x - prior) / (x + prior)
  sum(dif ** 2)
}

# equality constrants: heq(x) = 0
heq <- function(x) {
  (t(Amat[1:nx, 1:nc]) %*% x - bvec[1:nc])[, 1]
}

prior
fn_qp(prior)
fn_qp1(prior)
fn_mid(prior)
heq(prior) %>% round()

```

## alabama

Augmented Lagrangian Minimization (ALM) Algorithm.
Sensitive to initial point, likely gets stuck in local optima.

```{r}
sol_alm_qp <- alabama::auglag(
  par = prior,
  fn = fn_qp,
  hin = \(x) x,
  heq = heq
)

sol_alm_qp1 <- alabama::auglag(
  par = prior,
  fn = fn1,
  hin = \(x) x,
  heq = heq
)

sol_alm_qp_x0 <- alabama::auglag(
  par = sol_qp$solution[1:nx],
  fn = fn_qp,
  hin = \(x) x,
  heq = heq
)

sol_alm_qp_p0 <- alabama::auglag(
  par = rep(0, nx),
  fn = fn_qp,
  hin = \(x) x,
  heq = heq
)


sol_alm_qp_p1 <- alabama::auglag(
  par = prior / 3,
  fn = fn_qp,
  hin = \(x) x,
  heq = heq
)

sol_alm_mid <- alabama::auglag(
  par = prior,
  fn = fn_mid,
  hin = \(x) x,
  heq = heq
)


sol_alm_mid_x0 <- alabama::auglag(
  par = sol_qp$solution[1:nx],
  fn = fn_mid,
  hin = \(x) x,
  heq = heq
)


```


```{r}
cbind(
  prior,
  qp = sol_qp$solution[1:nx],
  alm_qp = sol_alm_qp$par,
  alm_qp1 = sol_alm_qp1$par,
  alm_qp_x0 = sol_alm_qp_x0$par,
  alm_qp_p0 = sol_alm_qp_p1$par,
  alm_qp_p1 = sol_alm_qp_p1$par,
  alm_mid = sol_alm_mid$par,
  alm_mid_x0 = sol_alm_mid_x0$par
) %>% round(0)
```


## nloptr ISRES

could not get to work: does not leave the starting point.

```{r}
upper <- df_2 %>%
  mutate(value = pmin(sp_bal, co_bal)) %>%
  pull(value, name = var)
upper <- upper[var_sol]

sol_isres <- nloptr::isres(
  x0 = pmin(prior, upper),
  fn = fn_mid,
  lower = rep(0, nx),
  upper = upper,
  heq = heq
)

sol_isres$message

heq(sol_isres$par)
heq(pmin(prior, upper))

```


## DEoptimR

Global optimum. Considerably slower than QP or ALM.


```{r}
upper <- df_2 %>%
  mutate(value = pmin(sp_bal, co_bal)) %>%
  pull(value, name = var)
upper <- upper[var_sol]

sol_jde_qp <- DEoptimR::JDEoptim(
  lower = rep(0, nx),
  upper = upper,
  fn = fn_qp,
  constr = heq,
  meq = nc,
  maxiter = 1e4
)

heq(sol_jde_qp$par)


sol_jde_mid <- DEoptimR::JDEoptim(
  lower = rep(0, nx),
  upper = upper,
  fn = fn_mid,
  constr = heq,
  meq = nc,
  maxiter = 1e4
)

heq(sol_jde_mid$par)

```



```{r}
cbind(
  prior,
  qp = sol_qp$solution[1:nx],
  alm = sol_alm_qp$par,
  jde = sol_jde$par,
  jde2 = sol_jde2$par
) %>% round(0)

plot(sol_qp$solution[1:nx], sol_jde2$par)
points(sol_qp$solution[1:nx], sol_alm_qp$par, pch = 3)
lines(c(0, 1e6), c(0, 1e6))
```


## OSQP

Alternative quadratic solver.
Code uses matrix forms prepared for the quadprog problem below.

```{r}
lb <- ab$b
ub <- ab$b
ub[nc + 1:nv] <- Inf
prob <- osqp::osqp(dmat, -dvec, ab$a, lb, ub)
system.time({
  sol_osqp <- prob$Solve()
})

solv_osqp <- sol_osqp$x[1:nv] %>%
  `names<-`(nmv)
sols_osqp <- sol_osqp$x[nv + 1:nc] %>%
  `names<-`(nms)
sols_osqp[sols_osqp > 5] %>% sort()

df_src %>%
  filter(id %in% nmv) %>%
  pivot_wider(id_cols = id, names_from = measure) %>%
  left_join(df_pri, "id") %>%
  left_join(solv %>% as_tibble(rownames = "id") %>% rename(qp = value), "id") %>%
  left_join(solv_osqp %>% as_tibble(rownames = "id") %>% rename(osqp = value), "id") %>%
  mutate(across(where(is.numeric), round)) %>%
  arrange(id)



```

## CVXR

Convex problem solver.
Can be used to allow non-quadratic penalty.
Uses data created for the quadprog problem below.

```{r}
library(CVXR)


df <- df_con %>%
  filter(id %in% (gr_con %>% filter(component == 44) %>% pull(name)))
d1 <- df %>%
  mutate(a = if_else(id == id_par, -1, 1), id_conpar = paste(id_con, id_par, sep = ":")) %>%
  pivot_wider(id_cols = c(id_conpar, value_bal), names_from = id, values_from = a, values_fill = 0)

bvec <- d1 %>%
  pull(value_bal, name = id_conpar)
amat <- d1 %>%
  select(!value_bal) %>%
  column_to_rownames("id_conpar") %>%
  as.matrix()
ab <- slack_and_zero(amat, bvec)



### objective function: D-mat and d-vec
nv <- ncol(amat)
nmv <- colnames(amat)
nc <- nrow(amat)
nmc <- rownames(amat)
nms <- paste0("s_", nmc)

pri <- df_pri %>%
  pull(prior, name = id)
pri <- pri[nmv]

dvec <- c(1 / pri, rep(0, nc))
names(dvec) <- c(nmv, nms)
dmat <- diag(c(1 / pri**2, rep(1, nc))) %>%
  `rownames<-`(names(dvec)) %>%
  `colnames<-`(names(dvec))

x <- Variable(nv, name = "x")
s <- Variable(nc, name = "s")
obj <- sum(((x - pri) / pri)^2) + sum(s^2)
prob <- Problem(Minimize(obj), constraints = list(x >= 0, amat %*% x + s == bvec))
res <- solve(prob)

res
xh <- res$getValue(x)[, 1]
sh <- res$getValue(s)[, 1]
objh <- sum(((xh - pri) / pri)^2) + sum(sh^2)
conh <- amat %*% xh + sh - bvec

df_src %>%
  filter(id %in% nmv) %>%
  pivot_wider(id_cols = id, names_from = measure) %>%
  left_join(df_pri, "id") %>%
  left_join(solv %>% as_tibble(rownames = "id") %>% rename(qp = value), "id") %>%
  left_join(tibble(id = nmv, cvx = xh), "id") %>%
  mutate(across(where(is.numeric), round)) %>%
  arrange(id)

# not the same!?
objh
res$getValue(obj)
```



# Complete set of constraints

New implementation for quadprog solver with all constraints.

## source data


Variable identifier: `00_000_00_000_0000` = (state, county, crop/anim, commodity-2, commodity-3)


```{r}

farm_sales <- function() {
  year <- 2012
  
  renames <- tribble(
    ~name,            ~short_desc,
    "nsal.00",          "COMMODITY TOTALS - OPERATIONS WITH SALES",
    "nsal.1c",          "CROP TOTALS - OPERATIONS WITH SALES",
    "nsal.1c_1gr",      "GRAIN - OPERATIONS WITH SALES",
    "nsal.1c_1gr_1cor", "CORN - OPERATIONS WITH SALES",
    "nsal.1c_1gr_2whe", "WHEAT - OPERATIONS WITH SALES",
    "nsal.1c_1gr_3soy", "SOYBEANS - OPERATIONS WITH SALES",
    "nsal.1c_1gr_4sor", "SORGHUM - OPERATIONS WITH SALES",
    "nsal.1c_1gr_5bar", "BARLEY - OPERATIONS WITH SALES",
    "nsal.1c_1gr_6ric", "RICE - OPERATIONS WITH SALES",
    "nsal.1c_1gr_7oth", "GRAIN, OTHER - OPERATIONS WITH SALES",
    "nsal.1c_2to",      "TOBACCO - OPERATIONS WITH SALES",
    "nsal.1c_3co",      "COTTON, LINT & SEED - OPERATIONS WITH SALES",
    "nsal.1c_4ve",      "VEGETABLE TOTALS, INCL SEEDS & TRANSPLANTS, IN THE OPEN - OPERATIONS WITH SALES",
    "nsal.1c_5fr",      "FRUIT & TREE NUT TOTALS - OPERATIONS WITH SALES",
    "nsal.1c_5fr_1tre", "FRUIT & TREE NUT TOTALS, (EXCL BERRIES) - OPERATIONS WITH SALES",
    "nsal.1c_5fr_2ber", "BERRY TOTALS - OPERATIONS WITH SALES",
    "nsal.1c_6ho",      "HORTICULTURE TOTALS, (EXCL CUT TREES & VEGETABLE SEEDS & TRANSPLANTS) - OPERATIONS WITH SALES",
    "nsal.1c_7tr",      "CUT CHRISTMAS TREES & SHORT TERM WOODY CROPS - OPERATIONS WITH SALES",
    "nsal.1c_7tr_1chr", "CUT CHRISTMAS TREES - OPERATIONS WITH SALES",
    "nsal.1c_7tr_2sho", "SHORT TERM WOODY CROPS - OPERATIONS WITH SALES",
    "nsal.1c_8ot",      "FIELD CROPS, OTHER, INCL HAY - OPERATIONS WITH SALES",
    "nsal.2a",          "ANIMAL TOTALS, INCL PRODUCTS - OPERATIONS WITH SALES",
    "nsal.2a_1po",      "POULTRY TOTALS, INCL EGGS - OPERATIONS WITH SALES",
    "nsal.2a_2ca",      "CATTLE, INCL CALVES - OPERATIONS WITH SALES",
    "nsal.2a_3mi",      "MILK - OPERATIONS WITH SALES",
    "nsal.2a_4hg",      "HOGS - OPERATIONS WITH SALES",
    "nsal.2a_5sh",      "SHEEP & GOATS TOTALS, INCL WOOL & MOHAIR & MILK - OPERATIONS WITH SALES",
    "nsal.2a_6hr",      "EQUINE, (HORSES & PONIES, OWNED) & (MULES & BURROS & DONKEYS, ANY) - OPERATIONS WITH SALES",
    "nsal.2a_7aq",      "AQUACULTURE TOTALS - OPERATIONS WITH SALES & DISTRIBUTION",
    "nsal.2a_8ot",      "SPECIALTY ANIMAL TOTALS, (EXCL EQUINE) - OPERATIONS WITH SALES",
    "sale.00",          "COMMODITY TOTALS - SALES, MEASURED IN $",
    "sale.1c",          "CROP TOTALS - SALES, MEASURED IN $",
    "sale.1c_1gr",      "GRAIN - SALES, MEASURED IN $",
    "sale.1c_1gr_1cor", "CORN - SALES, MEASURED IN $",
    "sale.1c_1gr_2whe", "WHEAT - SALES, MEASURED IN $",
    "sale.1c_1gr_3soy", "SOYBEANS - SALES, MEASURED IN $",
    "sale.1c_1gr_4sor", "SORGHUM - SALES, MEASURED IN $",
    "sale.1c_1gr_5bar", "BARLEY - SALES, MEASURED IN $",
    "sale.1c_1gr_6ric", "RICE - SALES, MEASURED IN $",
    "sale.1c_1gr_7oth", "GRAIN, OTHER - SALES, MEASURED IN $",
    "sale.1c_2to",      "TOBACCO - SALES, MEASURED IN $",
    "sale.1c_3co",      "COTTON, LINT & SEED - SALES, MEASURED IN $",
    "sale.1c_4ve",      "VEGETABLE TOTALS, INCL SEEDS & TRANSPLANTS, IN THE OPEN - SALES, MEASURED IN $",
    "sale.1c_5fr",      "FRUIT & TREE NUT TOTALS - SALES, MEASURED IN $",
    "sale.1c_5fr_1tre", "FRUIT & TREE NUT TOTALS, (EXCL BERRIES) - SALES, MEASURED IN $",
    "sale.1c_5fr_2ber", "BERRY TOTALS - SALES, MEASURED IN $",
    "sale.1c_6ho",      "HORTICULTURE TOTALS, (EXCL CUT TREES & VEGETABLE SEEDS & TRANSPLANTS) - SALES, MEASURED IN $",
    "sale.1c_7tr",      "CUT CHRISTMAS TREES & SHORT TERM WOODY CROPS - SALES, MEASURED IN $",
    "sale.1c_7tr_1chr", "CUT CHRISTMAS TREES - SALES, MEASURED IN $",
    "sale.1c_7tr_2sho", "SHORT TERM WOODY CROPS - SALES, MEASURED IN $",
    "sale.1c_8ot",      "FIELD CROPS, OTHER, INCL HAY - SALES, MEASURED IN $",
    "sale.2a",          "ANIMAL TOTALS, INCL PRODUCTS - SALES, MEASURED IN $",
    "sale.2a_1po",      "POULTRY TOTALS, INCL EGGS - SALES, MEASURED IN $",
    "sale.2a_2ca",      "CATTLE, INCL CALVES - SALES, MEASURED IN $",
    "sale.2a_3mi",      "MILK - SALES, MEASURED IN $",
    "sale.2a_4hg",      "HOGS - SALES, MEASURED IN $",
    "sale.2a_5sh",      "SHEEP & GOATS TOTALS, INCL WOOL & MOHAIR & MILK - SALES, MEASURED IN $",
    "sale.2a_6hr",      "EQUINE, (HORSES & PONIES, OWNED) & (MULES & BURROS & DONKEYS, ANY) - SALES, MEASURED IN $",
    "sale.2a_7aq",      "AQUACULTURE TOTALS - SALES & DISTRIBUTION, MEASURED IN $",
    "sale.2a_8ot",      "SPECIALTY ANIMAL TOTALS, (EXCL EQUINE) - SALES, MEASURED IN $"
  )
  
  agcensus_dataset(year) %>%
    filter(agg_level_desc %in% c("NATIONAL", "STATE", "COUNTY"), domain_desc == "TOTAL", short_desc %in% renames$short_desc) %>%
    mutate(
      id_sp1 = if_else(state_alpha == "US", "00", state_fips_code),
      id_sp2 = if_else(is.na(county_code), "000", county_code),
      id_sp = paste(id_sp1, id_sp2, sep = "_"),
    ) %>%
    select(id_sp1, id_sp2, id_sp, short_desc, value, value_f) %>%
    collect() %>%
    left_join(renames, "short_desc") %>%
    separate_wider_delim(name, delim = ".", names = c("measure", "commodity")) %>%
    separate_wider_delim(commodity, delim = "_", names = c("id_co1", "id_co2", "id_co3"), too_few = "align_start", cols_remove = FALSE) %>%
    mutate(
      id_co2 = replace_na(id_co2, "000"),
      id_co3 = replace_na(id_co3, "0000"),
      id_co = paste(id_co1, id_co2, id_co3, sep = "_"),
      id = paste(id_sp, id_co, sep = "_"),
      value = if_else(measure == "sale", value / 1000, value)
    ) %>%
    # ID hierarchy level
    mutate(
      lv_sp = case_when(
        id_sp1 == "00" ~ 0,
        id_sp2 == "000" ~ 1,
        .default = 2
      ),
      lv_co = case_when(
        id_co1 == "00" ~ 0,
        id_co2 == "000" ~ 1,
        id_co3 == "0000" ~ 2,
        .default = 3
      )
    ) %>%
    arrange(id, measure) %>%
    relocate(starts_with("id_"), measure, value)
}

df_src <- farm_sales()
df_src
```


## data overview

### code hierarchy

```{r}
#| rows.print: 100
farm_sales() %>%
  filter(measure == "sale", lv_sp == 0) %>%
  mutate(desc = str_sub(short_desc, 1, -24)) %>%
  arrange(id) %>%
  select(lv_co, commodity, desc, value)

```

### % missing

```{r}
#| rows.print: 100
df_src %>%
  filter(measure == "sale", lv_sp %in% c(0, 2)) %>%
  summarize(n = n(), nna = sum(!is.na(value)), sale = sum(value, na.rm = TRUE), .by = c("commodity", "lv_sp")) %>%
  pivot_wider(id_cols = commodity, names_from = lv_sp, values_from = c(n, nna, sale)) %>%
  select(commodity, nat_n = n_2, nat_sale = sale_0, cty_n = nna_2, cty_sale = sale_2) %>%
  mutate(
    pct_na_n = round(1 - cty_n / nat_n, 3) * 100,
    pct_na_sale = round(1 - cty_sale / nat_sale, 3) * 100
  ) %>%
  relocate(commodity, ends_with("_n"), ends_with("sale"))


```

### map


```{r}
library(tmap)
options(tigris_use_cache = TRUE)

tigris::counties(cb = TRUE, resolution = "20m", year = 2013) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) %>%
  inner_join(
    df_src %>% filter(measure == "nsal", commodity == "2a_3mi", lv_sp == 2),
    join_by(STATEFP == id_sp1, COUNTYFP == id_sp2)
  ) %>%
  tm_shape() +
  tm_polygons(
    "value", 
    fill.scale = tm_scale_intervals(
      style = "quantile", 
      label.format = scales::label_number(scale_cut = scales::cut_short_scale())
    ),
    fill.legend = tm_legend(
      title = "",
      orientation = "landscape",
      frame = FALSE
  )) +
  tm_layout(frame = FALSE) +
  tm_title("Milk: Farms")

tigris::counties(cb = TRUE, resolution = "20m", year = 2013) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) %>%
  inner_join(
    df_src %>% filter(measure == "sale", commodity == "2a_3mi", lv_sp == 2),
    join_by(STATEFP == id_sp1, COUNTYFP == id_sp2)
  ) %>%
  mutate(value = value * 1000) %>%
  tm_shape() +
  tm_polygons(
    "value", 
    fill.scale = tm_scale_intervals(
      style = "quantile", 
      label.format = scales::label_currency(scale_cut = scales::cut_short_scale())
    ),
    fill.legend = tm_legend(
      title = "",
      orientation = "landscape",
      frame = FALSE
  )) +
  tm_layout(frame = FALSE) +
  tm_title("Milk: Sales")

```



### group constraints

Issue in 2012: national grains != sum(grain types), data error?
Same imbalance number (2082) in the only state with missing data, Missoury (fips 29).

```{r}
# total number of non-zero commodities and number of NAs
farm_sales() %>%
  filter(measure == "sale", id_sp2 == "000") %>%
  summarize(n = n(), na = sum(is.na(value)), .by = id_sp1) %>%
  arrange(desc(n), na)
  
df <- farm_sales() %>%
  # filter(measure == "sale", id_sp1 == "00") %>%
  filter(measure == "sale", id_sp1 == "12", id_sp2 == "000") %>%
  select(id_co1, id_co2, id_co3, value) %>%
  arrange(id_co1, id_co2, id_co3)
df

# co0 = sum(co1)
df %>%
  filter(id_co2 == "000") %>%
  mutate(value = if_else(id_co1 == "00", value, -value), check = sum(value))

# co1 = sum(co2)
df %>%
  filter(id_co1 != "00", id_co3 == "0000") %>%
  mutate(value = if_else(id_co2 == "000", value, -value), check = sum(value), .by = id_co1)

# co2 = sum(co3)
df %>%
  filter(id_co2 != "000") %>%
  filter(n() > 1, .by = id_co2) %>%
  mutate(value = if_else(id_co3 == "0000", value, -value), check = sum(value), .by = id_co2)

```


## QP problem

TODO: review how zeroes are treated - there are no observations for them in the dataset


### constraints



```{r}

df_con <- list()

df <- df_src %>%
  filter(measure == "sale")
f <- function(x) {
  x %>%
    select(starts_with("id"), value) %>%
    # balance = parent value - sum of non-missing child values
    mutate(value_bal = sum(if_else(id == id_par, value, -value), na.rm = TRUE), .by = id_par) %>%
    filter(is.na(value)) %>%
    select(!value)
}

# nation = sum(state)
df_con[["sp1"]] <- df %>%
  filter(lv_sp %in% c(0, 1)) %>%
  mutate(id_par = `str_sub<-`(id, 1, 2, value = "00")) %>%
  f()

# state = sum(county)
df_con[["sp2"]] <- df %>%
  filter(lv_sp %in% c(1, 2)) %>%
  mutate(id_par = `str_sub<-`(id, 4, 6, value = "000")) %>%
  f()

# total = crop + animal
df_con[["co1"]] <- df %>%
  filter(lv_co %in% c(0, 1)) %>%
  mutate(id_par = `str_sub<-`(id, 8, 9, value = "00")) %>%
  f()

# crop and animal types
df_con[["co2"]] <- df %>%
  filter(lv_co %in% c(1, 2)) %>%
  mutate(id_par = `str_sub<-`(id, 11, 13, value = "000")) %>%
  f()

# subcrops
df_con[["co3"]] <- df %>%
  filter(lv_co %in% c(2, 3), paste(id_co1, id_co2, sep = "_") %in% c("1c_1gr", "1c_5fr", "1c_7tr")) %>%
  mutate(id_par = `str_sub<-`(id, 15, 18, value = "0000")) %>%
  f()

df_con <- bind_rows(df_con, .id = "id_con") %>%
  arrange(id_con, id_par, id) %>%
  relocate(id_con, id_par, id, value_bal)

df_con

```



```{r}
df_src %>%
  filter(id_sp == "01_007", str_detect(id_co, "1c_1gr")) %>%
  pivot_wider(id_cols = id, names_from = measure) %>%
  arrange(id) %>%
  left_join(df_prior, by = "id")

```

#### isolated subsets

The problem we end up with is quite large: 43,948 constraints and 20,452 variables.
How can we partition it?

A single constraint can thought of as a parent node connected to child nodes.
We can use network analysis to identify connected components - sets of constraints that share variables, only within themselves and not with other sets.


```{r}
library(tidygraph)

gr_con <- tbl_graph(edges = select(df_con, id_par, id)) %>%
  mutate(component = group_components())

df_con <- df_con %>%
  left_join(gr_con %>% as_tibble() %>% rename(id = name), "id")
stopifnot(!any(is.na(df_con$component)))

df_con %>%
  count(component) %>%
  arrange(n)

```

viz

```{r}
library(ggraph)

x <- gr_con %>%
  filter(component == 44)
x

x %>%
  ggraph(layout = "auto") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_graph()

```





### priors


Priors are based on geographic balances, proportional to number of farms in each child region with missing sales.
This is based on an assumption that average sales per farm are the same across all child regions with missing values for a given commodity.

Commodity balances could also be used, but they would rely on a seemingly stronger assumption that average sales per farm are the same for all child commodities with missing values for a given region.
Additional issue is that multiple farm can produce multiple child commodities.
This is not a problem for geographic balances, since each farm can only be in one child region.

If state value is known, priors can be calculated as in national balances.
If state value is missing, we can not apply same calculation, because unallocated balance is unknown.
We can not use state prior from the national balances, because it could be less than sum of known child county values.
Instead, we make another assumption that average sales per farm in missing counties is the same as average sales per farm in observed counties.

Possibilities:
- parent value known
- parent value unknown, some children known
- parent value unknown, children values unknown

```{r}
df0 <- df_src %>%
  pivot_wider(id_cols = c(id_co, lv_sp, id_sp, id_sp1, id), names_from = measure) %>%
  arrange(id_co, id_sp)

# parent level 0 (nation) - parent value always known
x_st_p1 <- df0 %>%
  filter(lv_sp %in% c(0, 1)) %>%
  group_by(id_co) %>%
  filter(any(is.na(sale))) %>%
  mutate(bal = sum(if_else(lv_sp == 0, sale, -sale), na.rm = TRUE)) %>%
  filter(is.na(sale)) %>%
  mutate(prior = nsal / sum(nsal) * bal) %>%
  ungroup()
# parent level 1 (state)
## parent value known
x_cty_p1 <- df0 %>%
  filter(lv_sp %in% c(1, 2)) %>%
  group_by(id_co, id_sp1) %>%
  filter(any(is.na(sale))) %>%
  filter(any(lv_sp == 1 & !is.na(sale))) %>%
  mutate(bal = sum(if_else(lv_sp == 1, sale, -sale), na.rm = TRUE)) %>%
  filter(is.na(sale)) %>%
  mutate(prior = nsal / sum(nsal) * bal) %>%
  ungroup()
## parent value unknown, some children known
x_cty_p2 <- df0 %>%
  filter(lv_sp %in% c(1, 2)) %>%
  group_by(id_co, id_sp1) %>%
  filter(any(is.na(sale))) %>%
  filter(!any(lv_sp == 1 & !is.na(sale))) %>%
  filter(any(lv_sp == 2 & !is.na(sale))) %>%
  mutate(
    sum_sale = sum(sale, na.rm = TRUE),
    sum_nsal = sum(if_else(is.na(sale), 0, nsal)),
    prior = nsal * sum_sale / sum_nsal
  ) %>%
  filter(is.na(sale), lv_sp == 2) %>%
  ungroup()
## parent value unknown, all children unknown
x_cty_p3 <- df0 %>%
  filter(lv_sp %in% c(1, 2)) %>%
  group_by(id_co, id_sp1) %>%
  filter(any(is.na(sale))) %>%
  filter(!any(lv_sp == 1 & !is.na(sale))) %>%
  filter(!any(lv_sp == 2 & !is.na(sale))) %>%
  left_join(
    df0 %>%
      filter(lv_sp == 0) %>%
      mutate(avg_sale = sale / nsal) %>%
      select(id_co, avg_sale),
    by = "id_co"
  ) %>%
  mutate(prior = nsal * avg_sale) %>%
  filter(lv_sp == 2) %>%
  ungroup()

df1 <- df0 %>%
  left_join(
    bind_rows(
      x_st_p1 %>% select(id, prior_1 = prior),
      x_cty_p1 %>% select(id, prior_1 = prior)
    ),
    by = "id"
  ) %>%
  left_join(x_cty_p2 %>% select(id, prior_2 = prior), by = "id") %>%
  left_join(x_cty_p3 %>% select(id, prior_3 = prior), by = "id")

x <- df1 %>%
  mutate(across(starts_with("prior"), round)) %>%
  filter(is.na(sale)) %>%
  rowwise() %>%
  mutate(np = sum(!is.na(prior_1), !is.na(prior_2), !is.na(prior_3)))
stopifnot(all(x$np == 1))

df_pri <- df1 %>%
  filter(is.na(sale)) %>%
  mutate(prior = case_when(
    !is.na(prior_1) ~ prior_1,
    !is.na(prior_2) ~ prior_2,
    .default = prior_3
  )) %>%
  select(id, prior)

# eyeball
x <- df1 %>% filter(id_sp1 == "10") %>% filter(any(!is.na(prior_1)), .by = id_co) %>% pull(id_co) %>% unique()
df1 %>% 
  filter(id_sp1 == "10") %>%
  filter(any(is.na(sale)), .by = id_co)

```




### matrix form

Takes 30 minutes to solve the largest (9,032 nodes) subset.

```{r}

#' add slack variables and non-negativity constraints to (A, b)
slack_and_zero <- function(a, b) {
  nv <- ncol(a)
  nc <- length(b)
  nmv <- colnames(a)
  nmc <- rownames(a)
  stopifnot(nrow(a) == nc)
  
  asl <- diag(1, nc) %>%
    `rownames<-`(nmc) %>%
    `colnames<-`(paste0("s_", nmc))
  
  aze <- diag(1, nv) %>%
    `rownames<-`(paste0("z_", nmv)) %>%
    `colnames<-`(nmv)
  bze <- rep(0, nv)
  
  a1 <- rbind(
    cbind(a, asl),
    cbind(aze, matrix(0, nv, nc))
  )
  b1 <- c(b, bze)
  
  list(a = a1, b = b1)
}

```



```{r}
solv <- c()
sols <- c()
df_stats <- tibble()

comps <- df_con %>%
  count(component) %>%
  arrange(n) %>%
  pull(component)

for (comp in comps) {
  t0 <- Sys.time()
  
  # 39: example with NA parent constraints, includes "50_009_1c_5fr_1tre"
  df <- df_con %>%
    filter(id %in% (gr_con %>% filter(component == comp) %>% pull(name)))
  df
  d1 <- df %>%
    mutate(a = if_else(id == id_par, -1, 1), id_conpar = paste(id_con, id_par, sep = ":")) %>%
    pivot_wider(id_cols = c(id_conpar, value_bal), names_from = id, values_from = a, values_fill = 0)
  
  bvec <- d1 %>%
    pull(value_bal, name = id_conpar)
  amat <- d1 %>%
    select(!value_bal) %>%
    column_to_rownames("id_conpar") %>%
    as.matrix()
  
  ab <- slack_and_zero(amat, bvec)
  
  ### objective function: D-mat and d-vec
  nv <- ncol(amat)
  nmv <- colnames(amat)
  nc <- nrow(amat)
  nmc <- rownames(amat)
  nms <- paste0("s_", nmc)
  
  pri <- df_pri %>%
    pull(prior, name = id)
  pri <- pri[nmv]
  
  dvec <- c(1 / pri, rep(0, nc))
  names(dvec) <- c(nmv, nms)
  dmat <- diag(c(1 / pri**2, rep(1, nc))) %>%
    `rownames<-`(names(dvec)) %>%
    `colnames<-`(names(dvec))
  
  system.time({
    sol <- quadprog::solve.QP(dmat, dvec, t(ab$a), ab$b, meq = nc)  
  })
  solv <- c(solv, sol$solution[1:nv] %>% `names<-`(nmv))
  sols <- c(sols, sol$solution[nv + 1:nc] %>% `names<-`(nms))

  x <- c(
    component = comp,
    variables = nv,
    constraints = nc,
    iterations = sol$iterations,
    # TODO: convert to seconds (longer times are in minutes)
    time = Sys.time() - t0
  )
  df_stats <- bind_rows(df_stats, x)
  print(x)
}


```



### solution

```{r}
df_solv <- df_src %>%
  pivot_wider(id_cols = id, names_from = measure) %>%
  left_join(df_pri, "id") %>%
  left_join(solv %>% as_tibble(rownames = "id") %>% rename(sol = value), "id") %>%
  arrange(id)

df_sols <- df_con %>%
  distinct(id_con, id_par) %>%
  left_join(
    sols %>% 
      as_tibble(rownames = "id_slk") %>%
      separate_wider_position(id_slk, c(2, id_con = 3, 1, id_par = 18)) %>%
      rename(slk = value), 
    c("id_con", "id_par")) %>%
  arrange(id_par)

# arrow::write_parquet(df_solv, "data/agcensus_imp_solv_2025-05-09.pq")
# arrow::write_parquet(df_sols, "data/agcensus_imp_sols_2025-05-09.pq")

quantile(df_sols$slk, c(0, 0.01, 0.05, 0.95, 0.99, 1))

df_solv %>%
  # mutate(across(where(is.numeric), round)) %>%
  filter(is.na(sale)) %>%
  select(!sale) %>%
  mutate(prior = prior + 1, sol = sol + 1) %>%
  ggplot() +
  geom_point(aes(prior, sol)) +
  scale_x_log10() + scale_y_log10()

df_solv

```

#### % missing

```{r}
#| rows.print: 100
df_solv %>%
  mutate(imp = if_else(is.na(sale), sol, sale)) %>%
  select(id, imp) %>%
  inner_join(df_src %>% filter(measure == "sale"), "id") %>%
  filter(lv_sp %in% c(0, 2)) %>%
  summarize(raw = sum(value, na.rm = TRUE), imp = round(sum(imp)), .by = c("commodity", "lv_sp")) %>%
  pivot_wider(id_cols = commodity, names_from = lv_sp, values_from = c(raw, imp)) %>%
  select(commodity, nation = raw_0, cty_raw = raw_2, cty_imp = imp_2) %>%
  mutate(pct_na_raw = round(1 - cty_raw / nation, 3) * 100, pct_na_imp = round(1 - cty_imp / nation, 3) * 100)

```







